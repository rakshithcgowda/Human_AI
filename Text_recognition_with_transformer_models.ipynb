{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvRp/4iHAQC+Rs1HDEG93k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakshithcgowda/Human_AI/blob/master/Text_recognition_with_transformer_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "id": "Hjmgu7o9UN-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "id": "dOFY3q7Wk9DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx"
      ],
      "metadata": {
        "id": "mrQtqEualgnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf /content/jpg_images"
      ],
      "metadata": {
        "id": "bhEo6Ou6Ut9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert form PDF to JPG"
      ],
      "metadata": {
        "id": "4zXeFLx03b6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path, pdfinfo_from_path\n",
        "\n",
        "def convert_pdf_to_jpg(pdf_dir, jpg_dir, dpi=200):\n",
        "    \"\"\"\n",
        "    Convert PDF files to JPG images. Each page of a PDF will be converted to a separate JPG image.\n",
        "\n",
        "    This version processes one page at a time, which can help reduce memory usage.\n",
        "\n",
        "    Args:\n",
        "        pdf_dir (str): Directory containing PDF files.\n",
        "        jpg_dir (str): Directory where the JPG images will be saved.\n",
        "        dpi (int): Resolution for converting PDF pages.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(jpg_dir):\n",
        "        os.makedirs(jpg_dir)\n",
        "\n",
        "    for filename in os.listdir(pdf_dir):\n",
        "        if filename.lower().endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_dir, filename)\n",
        "            try:\n",
        "                # Retrieve PDF information to get the total number of pages.\n",
        "                info = pdfinfo_from_path(pdf_path, userpw=None)\n",
        "                total_pages = info.get(\"Pages\", 0)\n",
        "                print(f\"Processing '{filename}' with {total_pages} pages.\")\n",
        "\n",
        "                # Process each page individually to reduce memory usage.\n",
        "                for page_number in range(1, total_pages + 1):\n",
        "                    # Convert only one page at a time.\n",
        "                    pages = convert_from_path(\n",
        "                        pdf_path, dpi=dpi, first_page=page_number, last_page=page_number\n",
        "                    )\n",
        "                    for page in pages:\n",
        "                        jpg_filename = os.path.splitext(filename)[0] + f\"_page{page_number}.jpg\"\n",
        "                        jpg_path = os.path.join(jpg_dir, jpg_filename)\n",
        "                        page.save(jpg_path, \"JPEG\")\n",
        "                        print(f\"Saved JPG image to {jpg_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {pdf_path}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Directories for PDF and JPG images.\n",
        "    pdf_folder = \"/content/pdf\"          # Directory with your PDF files\n",
        "    jpg_folder = \"/content/jpg_images\"     # Directory to save JPG images after conversion from PDF\n",
        "\n",
        "    # Convert PDF files to JPG images.\n",
        "    convert_pdf_to_jpg(pdf_folder, jpg_folder, dpi=200)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iX3-qq0VRjtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert JPG to Mask images"
      ],
      "metadata": {
        "id": "lKmmR67m3nB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def convert_jpgs_to_mask(jpg_dir, mask_dir, threshold=128):\n",
        "    \"\"\"\n",
        "    Convert JPG images to binary mask images using a simple threshold.\n",
        "\n",
        "    Args:\n",
        "        jpg_dir (str): Directory containing JPG images.\n",
        "        mask_dir (str): Directory where mask images will be saved.\n",
        "        threshold (int): Grayscale threshold value (0-255) to determine mask cutoff.\n",
        "                         Pixels with values above this threshold will be white (255),\n",
        "                         otherwise black (0).\n",
        "    \"\"\"\n",
        "    if not os.path.exists(mask_dir):\n",
        "        os.makedirs(mask_dir)\n",
        "\n",
        "    for filename in os.listdir(jpg_dir):\n",
        "        if filename.lower().endswith(\".jpg\"):\n",
        "            jpg_path = os.path.join(jpg_dir, filename)\n",
        "            try:\n",
        "                # Open the image and convert it to grayscale.\n",
        "                img = Image.open(jpg_path)\n",
        "                img_gray = img.convert(\"L\")\n",
        "\n",
        "                # Apply threshold to create a binary mask.\n",
        "                mask = img_gray.point(lambda p: 255 if p > threshold else 0)\n",
        "\n",
        "                # Save the mask image with a new name.\n",
        "                mask_filename = os.path.splitext(filename)[0] + \"_mask.png\"\n",
        "                mask_path = os.path.join(mask_dir, mask_filename)\n",
        "                mask.save(mask_path)\n",
        "                print(f\"Saved mask image to {mask_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {jpg_path}: {e}\")\n",
        "\n",
        "# -------------------------\n",
        "# Example usage:\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    jpg_folder = \"/content/jpg_images\"      # Directory with your existing JPG images\n",
        "    mask_output_folder = \"/content/mask_imgs\" # Directory to save the generated mask images\n",
        "    convert_jpgs_to_mask(jpg_folder, mask_output_folder, threshold=128)\n"
      ],
      "metadata": {
        "id": "CezfDQOVjicH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specific Task I - Layout Organization Recognition:"
      ],
      "metadata": {
        "id": "MEQgBfsE3yBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "###########################################\n",
        "# Note on Image Quality and OCR\n",
        "###########################################\n",
        "# If you use this model (or a similar one) for text segmentation/OCR tasks,\n",
        "# be aware that low resolution, blurriness, poor contrast, and other image artifacts\n",
        "# can lead to poor predictions. To help improve performance, consider:\n",
        "#   - Using high-resolution images\n",
        "#   - Ensuring proper lighting and contrast\n",
        "#   - Cropping out extraneous background or noise\n",
        "#\n",
        "# The mismatch between input clarity and predicted output is often due to these factors.\n",
        "\n",
        "###########################################\n",
        "# Dataset Class\n",
        "###########################################\n",
        "class LayoutDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.images = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_filename = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_filename)\n",
        "        mask_filename = f\"{os.path.splitext(img_filename)[0]}_mask.png\"\n",
        "        mask_path = os.path.join(self.mask_dir, mask_filename)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if os.path.exists(mask_path):\n",
        "            mask = Image.open(mask_path).convert(\"L\")\n",
        "        else:\n",
        "            print(f\"Warning: Missing mask for {img_filename}. Using blank mask.\")\n",
        "            mask = Image.new(\"L\", image.size, 0)\n",
        "\n",
        "        image = self.image_transform(image) if self.image_transform else transforms.ToTensor()(image)\n",
        "        mask = self.mask_transform(mask) if self.mask_transform else transforms.ToTensor()(mask)\n",
        "        # Convert mask to binary (0 and 1)\n",
        "        mask = (mask > 0.5).long().squeeze(0)\n",
        "        return image, mask\n",
        "\n",
        "###########################################\n",
        "# Building Blocks for Advanced Model\n",
        "###########################################\n",
        "# Residual Double Convolution Block\n",
        "class ResDoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResDoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Adjust dimensions if needed\n",
        "        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x if self.res_conv is None else self.res_conv(x)\n",
        "        out = self.double_conv(x)\n",
        "        out += residual\n",
        "        return self.relu(out)\n",
        "\n",
        "# Attention Block for Skip Connections\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "# Up Block with Attention on Skip Connections\n",
        "class UpAttention(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        \"\"\"\n",
        "        in_channels: number of channels from concatenated decoder and encoder features.\n",
        "        out_channels: desired number of output channels.\n",
        "        \"\"\"\n",
        "        super(UpAttention, self).__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "        # For the attention gate, assume both the upsampled feature and skip connection have half of in_channels each.\n",
        "        self.attention = AttentionBlock(F_g=in_channels // 2, F_l=in_channels // 2, F_int=in_channels // 4)\n",
        "        # After concatenation of features, use a residual double conv block.\n",
        "        self.conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_up, x_skip):\n",
        "        x_up = self.up(x_up)\n",
        "        # Ensure sizes match by padding if necessary.\n",
        "        diffY = x_skip.size()[2] - x_up.size()[2]\n",
        "        diffX = x_skip.size()[3] - x_up.size()[3]\n",
        "        x_up = F.pad(x_up, [diffX // 2, diffX - diffX // 2,\n",
        "                            diffY // 2, diffY - diffY // 2])\n",
        "        # Refine the skip connection with attention.\n",
        "        x_skip = self.attention(g=x_up, x=x_skip)\n",
        "        # Concatenate along the channel dimension.\n",
        "        x = torch.cat([x_skip, x_up], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "# Positional Encoding for Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # [max_len, 1]\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)  # [max_len, 1, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [seq_len, batch_size, d_model]\n",
        "        seq_len = x.size(0)\n",
        "        return x + self.pe[:seq_len]\n",
        "\n",
        "###########################################\n",
        "# AdvancedTransUNet: Refined Architecture\n",
        "###########################################\n",
        "class AdvancedTransUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True, transformer_layers=2, nhead=8):\n",
        "        super(AdvancedTransUNet, self).__init__()\n",
        "        # Encoder with residual blocks\n",
        "        self.inc = ResDoubleConv(n_channels, 64)         # [B, 64, H, W]\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(64, 128))   # [B, 128, H/2, W/2]\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(128, 256))  # [B, 256, H/4, W/4]\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(256, 512))  # [B, 512, H/8, W/8]\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(512, 1024 // factor))  # [B, 1024//factor, H/16, W/16]\n",
        "\n",
        "        self.feature_dim = 1024 // factor  # Bottleneck channels\n",
        "\n",
        "        # Projection layer (if needed) and positional encoding before transformer\n",
        "        self.transformer_input_proj = nn.Conv2d(self.feature_dim, self.feature_dim, kernel_size=1)\n",
        "        self.pos_encoder = PositionalEncoding(d_model=self.feature_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.feature_dim, nhead=nhead)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=transformer_layers)\n",
        "\n",
        "        # Decoder with Attention-based Up Blocks\n",
        "        # Note: in_channels here is the sum of channels from upsampled feature and corresponding encoder skip.\n",
        "        self.up1 = UpAttention(in_channels=1024, out_channels=256, bilinear=bilinear)  # x5 (512) + x4 (512) = 1024 -> 256\n",
        "        self.up2 = UpAttention(in_channels=512, out_channels=128, bilinear=bilinear)   # 256 + 256 = 512 -> 128\n",
        "        self.up3 = UpAttention(in_channels=256, out_channels=64, bilinear=bilinear)    # 128 + 128 = 256 -> 64\n",
        "        self.up4 = UpAttention(in_channels=128, out_channels=64, bilinear=bilinear)    # 64 + 64 = 128 -> 64\n",
        "\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        x1 = self.inc(x)       # [B, 64, H, W]\n",
        "        x2 = self.down1(x1)    # [B, 128, H/2, W/2]\n",
        "        x3 = self.down2(x2)    # [B, 256, H/4, W/4]\n",
        "        x4 = self.down3(x3)    # [B, 512, H/8, W/8]\n",
        "        x5 = self.down4(x4)    # [B, feature_dim, H/16, W/16]\n",
        "\n",
        "        # Bottleneck with transformer\n",
        "        x5 = self.transformer_input_proj(x5)\n",
        "        B, C, H, W = x5.shape\n",
        "        x5_flat = x5.view(B, C, H * W).permute(2, 0, 1)  # [seq_len, B, C]\n",
        "        x5_flat = self.pos_encoder(x5_flat)\n",
        "        x5_trans = self.transformer(x5_flat)\n",
        "        x5 = x5_trans.permute(1, 2, 0).view(B, C, H, W)\n",
        "\n",
        "        # Decoder with attention-enhanced skip connections\n",
        "        x = self.up1(x5, x4)   # Combines bottleneck and encoder feature x4\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        return self.outc(x)\n",
        "\n",
        "###########################################\n",
        "# Evaluation Metrics: IoU and Dice Coefficient\n",
        "###########################################\n",
        "def compute_iou(pred, target, smooth=1e-6):\n",
        "    intersection = (pred & target).float().sum((1, 2))\n",
        "    union = (pred | target).float().sum((1, 2))\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou.mean().item()\n",
        "\n",
        "def compute_dice(pred, target, smooth=1e-6):\n",
        "    intersection = (pred * target).float().sum((1, 2))\n",
        "    dice = (2 * intersection + smooth) / (pred.float().sum((1, 2)) + target.float().sum((1, 2)) + smooth)\n",
        "    return dice.mean().item()\n",
        "\n",
        "###########################################\n",
        "# Training and Evaluation Functions\n",
        "###########################################\n",
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)  # [B, n_classes, H, W]\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_iou = 0\n",
        "    total_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            total_iou += compute_iou(preds, masks)\n",
        "            total_dice += compute_dice(preds, masks)\n",
        "    return total_iou / len(loader), total_dice / len(loader)\n",
        "\n",
        "###########################################\n",
        "# Main Training Routine\n",
        "###########################################\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    img_dir = \"/content/jpg_images\"  # Folder with JPG images\n",
        "    mask_dir = \"/content/mask_imgs\"  # Folder with corresponding _mask.png files\n",
        "\n",
        "    # Define transforms: resize images and masks to 256x256\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = LayoutDataset(img_dir, mask_dir, image_transform=transform, mask_transform=transform)\n",
        "    train_len = int(0.8 * len(dataset))\n",
        "    train_set, val_set = random_split(dataset, [train_len, len(dataset) - train_len])\n",
        "    train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "\n",
        "    # Create the advanced model\n",
        "    model = AdvancedTransUNet(n_channels=3, n_classes=2, bilinear=True, transformer_layers=2, nhead=8).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    num_epochs = 5\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        iou, dice = evaluate(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch}/{num_epochs} - Loss: {train_loss:.4f} - Val IoU: {iou:.4f} - Val Dice: {dice:.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"advanced_transunet_model.pth\")\n",
        "    print(\"Training complete. Model saved as 'advanced_transunet_model.pth'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "u_U7hForoZ9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7467169-a3ef-4582-feeb-24370201b591"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3402: DecompressionBombWarning: Image size (94080000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 0.2443 - Val IoU: 0.9144 - Val Dice: 0.9546\n",
            "Epoch 2/5 - Loss: 0.0934 - Val IoU: 0.9150 - Val Dice: 0.9549\n",
            "Epoch 3/5 - Loss: 0.1003 - Val IoU: 0.9532 - Val Dice: 0.9759\n",
            "Epoch 4/5 - Loss: 0.1296 - Val IoU: 0.9584 - Val Dice: 0.9787\n",
            "Epoch 5/5 - Loss: 0.0829 - Val IoU: 0.9831 - Val Dice: 0.9915\n",
            "Training complete. Model saved as 'advanced_transunet_model.pth'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##STEP 2"
      ],
      "metadata": {
        "id": "pGYDrzBPpFmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "v23ulPTIpeVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excel file\n"
      ],
      "metadata": {
        "id": "fv2SVQsN9wR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rm -rf /content/ocr_images"
      ],
      "metadata": {
        "id": "PSN-bl1zcsm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting a Word Document to OCR Images and Labels"
      ],
      "metadata": {
        "id": "2qVKbZRx94dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "7IBdSEB4R334"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from docx import Document\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def convert_multiple_docs_to_ocr(docx_dir, output_image_dir, output_text_dir):\n",
        "    \"\"\"\n",
        "    Extracts text from multiple Word documents, processes each page separately,\n",
        "    and saves the output as text files and images.\n",
        "\n",
        "    Parameters:\n",
        "      docx_dir (str): Directory containing Word (.docx) files.\n",
        "      output_image_dir (str): Directory to save the rendered images.\n",
        "      output_text_dir (str): Directory to save the extracted text files.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_image_dir, exist_ok=True)\n",
        "    os.makedirs(output_text_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate through all .docx files in the directory\n",
        "    for file in os.listdir(docx_dir):\n",
        "        if file.endswith(\".docx\"):\n",
        "            word_path = os.path.join(docx_dir, file)\n",
        "            doc = Document(word_path)\n",
        "            base_filename = os.path.splitext(file)[0]\n",
        "\n",
        "            for i, para in enumerate(doc.paragraphs):\n",
        "                page_text = para.text.strip()\n",
        "                if not page_text:\n",
        "                    continue  # Skip empty pages\n",
        "\n",
        "                # Save extracted text\n",
        "                text_filename = f\"{base_filename}_page_{i+1}.txt\"\n",
        "                text_path = os.path.join(output_text_dir, text_filename)\n",
        "                with open(text_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(page_text)\n",
        "\n",
        "                # Render text to image\n",
        "                font = ImageFont.load_default()\n",
        "                lines = page_text.splitlines() or [\" \"]\n",
        "                line_height = font.getbbox('A')[3] - font.getbbox('A')[1] + 2\n",
        "                max_line_width = max([font.getbbox(line)[2] - font.getbbox(line)[0] for line in lines])\n",
        "                img_width = max_line_width + 20\n",
        "                img_height = line_height * len(lines) + 20\n",
        "                image = Image.new('L', (img_width, img_height), color=255)\n",
        "                draw = ImageDraw.Draw(image)\n",
        "\n",
        "                y_text = 10\n",
        "                for line in lines:\n",
        "                    draw.text((10, y_text), line, fill=0, font=font)\n",
        "                    y_text += line_height\n",
        "\n",
        "                # Save image\n",
        "                image_filename = f\"{base_filename}_page_{i+1}.jpg\"\n",
        "                image_path = os.path.join(output_image_dir, image_filename)\n",
        "                image.save(image_path)\n",
        "\n",
        "                print(f\"Processed {file}, Page {i+1}: Saved text to {text_path} and image to {image_path}.\")\n",
        "\n",
        "# Example usage:\n",
        "docx_directory = \"/content/word\"\n",
        "image_output_directory = \"ocr_images\"\n",
        "text_output_directory = \"ocr_texts\"\n",
        "convert_multiple_docs_to_ocr(docx_directory, image_output_directory, text_output_directory)\n"
      ],
      "metadata": {
        "id": "oNKJkr2X9-fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specific Task II - Optical Character Recognition (OCR):\n"
      ],
      "metadata": {
        "id": "0yxhp7cyGsH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import editdistance  # pip install editdistance\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# ----- Character Set & Label Conversion Utilities -----\n",
        "# We use a character set covering lowercase letters (with accented characters) and digits.\n",
        "# (Note: In this version we include a space token as the last character.)\n",
        "CHAR_SET = \"abcdefghijklmnopqrstuvwxyzáéíóúüñ0123456789,.?`~ \"\n",
        "# For CTC, index 0 is reserved for the blank token.\n",
        "char_to_idx = {char: idx + 1 for idx, char in enumerate(CHAR_SET)}\n",
        "idx_to_char = {idx + 1: char for idx, char in enumerate(CHAR_SET)}\n",
        "\n",
        "def text_to_labels(text):\n",
        "    \"\"\"Convert a string to a list of label indices.\"\"\"\n",
        "    return [char_to_idx[char] for char in text.lower() if char in char_to_idx]\n",
        "\n",
        "def labels_to_text(labels):\n",
        "    \"\"\"Convert a list of label indices to a string.\"\"\"\n",
        "    return \"\".join([idx_to_char[label] for label in labels if label in idx_to_char])\n",
        "\n",
        "# ----- Custom Dataset -----\n",
        "class OCRDataset(data.Dataset):\n",
        "    def __init__(self, image_dir, text_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (str): Directory containing OCR images (.jpg).\n",
        "            text_dir (str): Directory containing corresponding text files (.txt).\n",
        "            transform: Optional torchvision transforms to apply.\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.text_dir = text_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # List image and text files (case-insensitive).\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')])\n",
        "        self.text_files = sorted([f for f in os.listdir(text_dir) if f.lower().endswith('.txt')])\n",
        "\n",
        "        print(\"Found image files:\", self.image_files)\n",
        "        print(\"Found text files:\", self.text_files)\n",
        "\n",
        "        if len(self.image_files) == 0 or len(self.text_files) == 0:\n",
        "            raise ValueError(\"No files found in the given directories.\")\n",
        "        assert len(self.image_files) == len(self.text_files), \"Mismatch between images and text files.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image and convert to grayscale.\n",
        "        img_file = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_file)\n",
        "        image = Image.open(img_path).convert('L')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        # Load the corresponding ground truth text.\n",
        "        text_file = self.text_files[idx]\n",
        "        text_path = os.path.join(self.text_dir, text_file)\n",
        "        with open(text_path, 'r', encoding='utf-8') as f:\n",
        "            gt_text = f.read().strip()\n",
        "        label = torch.tensor(text_to_labels(gt_text), dtype=torch.long)\n",
        "\n",
        "        return image, gt_text, label, len(label), img_file\n",
        "\n",
        "# ----- Hybrid CNN + Transformer Model -----\n",
        "class HybridOCRTransformer(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        \"\"\"\n",
        "        A hybrid model using a CNN backbone to extract spatial features followed by a Transformer encoder\n",
        "        to model the sequence. This architecture is inspired by recent research on transformer-based OCR\n",
        "        for historical texts.\n",
        "        Expects input images of shape (batch, 1, 32, 128).\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of output classes (len(CHAR_SET) + 1 for blank).\n",
        "        \"\"\"\n",
        "        super(HybridOCRTransformer, self).__init__()\n",
        "        # CNN Backbone: extract spatial features\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # (32,128) -> (32,128)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),                         # (32,128) -> (16,64)\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # (16,64) -> (16,64)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),                         # (16,64) -> (8,32)\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),# (8,32) -> (8,32)\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)                          # (8,32) -> (4,16)\n",
        "        )\n",
        "        # After the CNN, feature map shape: (batch, 256, 4, 16)\n",
        "        # Flatten spatial dimensions to obtain a sequence of length 4*16 = 64, with feature dimension 256.\n",
        "        self.sequence_length = 4 * 16  # 64\n",
        "\n",
        "        # Transformer Encoder for sequence modeling.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8, dropout=0.1)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
        "\n",
        "        # Final classification layer on each time step.\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, 1, 32, 128)\n",
        "        features = self.cnn_backbone(x)  # -> (batch, 256, 4, 16)\n",
        "        batch, C, H, W = features.size()\n",
        "        # Flatten spatial dimensions: create sequence of shape (batch, H*W, C)\n",
        "        features = features.view(batch, C, H * W).permute(0, 2, 1)  # (batch, 64, 256)\n",
        "        # Transformer expects (sequence_length, batch, d_model)\n",
        "        features = features.permute(1, 0, 2)  # (64, batch, 256)\n",
        "        encoded = self.transformer_encoder(features)  # (64, batch, 256)\n",
        "        encoded = encoded.permute(1, 0, 2)  # (batch, 64, 256)\n",
        "        logits = self.fc(encoded)  # (batch, 64, num_classes)\n",
        "        return logits\n",
        "\n",
        "# ----- Greedy Decoder for CTC Outputs -----\n",
        "def greedy_decoder(output, blank=0):\n",
        "    \"\"\"\n",
        "    Decodes the raw output logits of shape (T, B, num_classes)\n",
        "    into predicted text strings for each batch element.\n",
        "    \"\"\"\n",
        "    # Compute argmax over classes at each time step.\n",
        "    arg_maxes = torch.argmax(output, dim=2)  # (T, B)\n",
        "    decoded_preds = []\n",
        "    for args in arg_maxes.transpose(0, 1):  # iterate over batch\n",
        "        pred = []\n",
        "        prev = blank\n",
        "        for idx in args:\n",
        "            idx = idx.item()\n",
        "            if idx != prev and idx != blank:\n",
        "                pred.append(idx)\n",
        "            prev = idx\n",
        "        decoded_preds.append(labels_to_text(pred))\n",
        "    return decoded_preds\n",
        "\n",
        "# ----- Collate Function for DataLoader -----\n",
        "def ocr_collate_fn(batch):\n",
        "    images, texts, labels, label_lengths, filenames = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    label_lengths = torch.tensor(label_lengths, dtype=torch.long)\n",
        "    labels_concat = torch.cat(labels)\n",
        "    return images, texts, labels_concat, label_lengths, filenames\n",
        "\n",
        "# ----- Evaluation Function for CER, WER and BLEU -----\n",
        "def evaluate_samples_and_plot(model, eval_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluates the OCR model on individual samples, computing the Character Error Rate (CER),\n",
        "    Word Error Rate (WER) and BLEU score for each sample, then plots the distribution of CER and WER.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    cer_list = []\n",
        "    wer_list = []\n",
        "    bleu_list = []\n",
        "    smoothing = SmoothingFunction().method1  # Smoothing function for BLEU\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, texts, _, _, _ in eval_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)  # (batch, sequence, num_classes)\n",
        "            outputs = outputs.permute(1, 0, 2)  # (sequence, batch, num_classes)\n",
        "            preds = greedy_decoder(outputs)\n",
        "            pred = preds[0]\n",
        "            gt_text = texts[0]\n",
        "            # Compute CER: edit distance normalized by length of ground truth.\n",
        "            cer = editdistance.eval(pred, gt_text) / len(gt_text) if len(gt_text) > 0 else 0\n",
        "            # Compute WER: tokenize texts by space and compute edit distance.\n",
        "            pred_words = pred.split()\n",
        "            gt_words = gt_text.split()\n",
        "            wer = editdistance.eval(pred_words, gt_words) / len(gt_words) if len(gt_words) > 0 else 0\n",
        "            # Compute BLEU score (using tokenized words).\n",
        "            # Using a list of reference tokens and candidate tokens.\n",
        "            bleu = sentence_bleu([gt_words], pred_words, smoothing_function=smoothing)\n",
        "\n",
        "            cer_list.append(cer)\n",
        "            wer_list.append(wer)\n",
        "            bleu_list.append(bleu)\n",
        "\n",
        "            # Print predicted and ground truth texts along with their metrics.\n",
        "            print(f\"Ground Truth: {gt_text}\")\n",
        "            print(f\"Predicted   : {pred}\")\n",
        "            print(f\"CER: {cer:.3f}, WER: {wer:.3f}, BLEU: {bleu:.3f}\\n\")\n",
        "\n",
        "    avg_cer = sum(cer_list) / len(cer_list)\n",
        "    avg_wer = sum(wer_list) / len(wer_list)\n",
        "    avg_bleu = sum(bleu_list) / len(bleu_list)\n",
        "    print(f\"Average CER: {avg_cer:.3f}\")\n",
        "    print(f\"Average WER: {avg_wer:.3f}\")\n",
        "    print(f\"Average BLEU: {avg_bleu:.3f}\")\n",
        "\n",
        "    # Plot histogram of CER and WER\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(cer_list, bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
        "    plt.title(\"CER Distribution\")\n",
        "    plt.xlabel(\"CER\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(wer_list, bins=10, color=\"salmon\", edgecolor=\"black\")\n",
        "    plt.title(\"WER Distribution\")\n",
        "    plt.xlabel(\"WER\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----- Main Training and Evaluation Routine -----\n",
        "def train_and_evaluate(image_dir, text_dir, img_height=32, img_width=128,\n",
        "                       num_epochs=110, batch_size=8, learning_rate=0.0005):\n",
        "    \"\"\"\n",
        "    This routine trains the hybrid CNN+Transformer model using CTC loss.\n",
        "    After training, it computes the character error rate (CER), word error rate (WER),\n",
        "    and BLEU score for each sample and then plots the results.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_height, img_width)),\n",
        "        transforms.ToTensor(),  # scales pixel values to [0,1]\n",
        "    ])\n",
        "\n",
        "    dataset = OCRDataset(image_dir, text_dir, transform=transform)\n",
        "    train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=ocr_collate_fn)\n",
        "\n",
        "    num_classes = len(CHAR_SET) + 1  # +1 for the blank token\n",
        "    model = HybridOCRTransformer(num_classes=num_classes)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # CTC Loss expects raw logits.\n",
        "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    print(\"Starting training of the hybrid CNN+Transformer model...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for batch_idx, (images, _, labels, label_lengths, _) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)  # (batch, sequence, num_classes)\n",
        "            outputs = outputs.permute(1, 0, 2)  # (sequence, batch, num_classes)\n",
        "            batch_size_actual = images.size(0)\n",
        "            input_lengths = torch.full(size=(batch_size_actual,), fill_value=outputs.size(0), dtype=torch.long)\n",
        "\n",
        "            loss = ctc_loss(outputs, labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {epoch_loss/len(train_loader):.4f}\\n\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"hybrid_ocr_transformer.pth\")\n",
        "    print(\"Training complete and model saved as 'hybrid_ocr_transformer.pth'.\\n\")\n",
        "\n",
        "    # Evaluate the model on individual samples using CER, WER and BLEU, then plot results.\n",
        "    eval_loader = data.DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=ocr_collate_fn)\n",
        "    print(\"Evaluating model on individual samples (CER, WER & BLEU):\")\n",
        "    evaluate_samples_and_plot(model, eval_loader, device)\n",
        "\n",
        "# ----- Example Usage -----\n",
        "if __name__ == \"__main__\":\n",
        "    # Set these directories to point to your OCR images (JPG) and ground truth texts (TXT).\n",
        "    image_directory = \"/content/ocr_images\"  # Directory containing .jpg files.\n",
        "    text_directory = \"/content/ocr_texts\"      # Directory containing corresponding .txt files.\n",
        "\n",
        "    # Adjust hyperparameters as needed. Here we use 100 epochs for demonstration.\n",
        "    train_and_evaluate(image_directory, text_directory, img_height=32, img_width=128,\n",
        "                       num_epochs=110, batch_size=8, learning_rate=0.0005)\n"
      ],
      "metadata": {
        "id": "xsF2ZT4mcsdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc07dd1e-568a-4398-9fe0-44d70510f22e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found image files: ['Buendia transcription_page_1.jpg', 'Buendia transcription_page_10.jpg', 'Buendia transcription_page_2.jpg', 'Buendia transcription_page_3.jpg', 'Buendia transcription_page_4.jpg', 'Buendia transcription_page_5.jpg', 'Buendia transcription_page_6.jpg', 'Buendia transcription_page_7.jpg', 'Buendia transcription_page_8.jpg', 'Buendia transcription_page_9.jpg', 'Constituciones sinodales transcription_page_1.jpg', 'Constituciones sinodales transcription_page_10.jpg', 'Constituciones sinodales transcription_page_11.jpg', 'Constituciones sinodales transcription_page_2.jpg', 'Constituciones sinodales transcription_page_3.jpg', 'Constituciones sinodales transcription_page_4.jpg', 'Constituciones sinodales transcription_page_5.jpg', 'Constituciones sinodales transcription_page_6.jpg', 'Constituciones sinodales transcription_page_7.jpg', 'Constituciones sinodales transcription_page_8.jpg', 'Constituciones sinodales transcription_page_9.jpg', 'Ezcaray transcription_page_1.jpg', 'Ezcaray transcription_page_2.jpg', 'Ezcaray transcription_page_3.jpg', 'Ezcaray transcription_page_4.jpg', 'Ezcaray transcription_page_5.jpg', 'Ezcaray transcription_page_6.jpg', 'Ezcaray transcription_page_7.jpg', 'Ezcaray transcription_page_8.jpg', 'Mendo transcription_page_1.jpg', 'Mendo transcription_page_10.jpg', 'Mendo transcription_page_100.jpg', 'Mendo transcription_page_101.jpg', 'Mendo transcription_page_102.jpg', 'Mendo transcription_page_103.jpg', 'Mendo transcription_page_104.jpg', 'Mendo transcription_page_105.jpg', 'Mendo transcription_page_106.jpg', 'Mendo transcription_page_107.jpg', 'Mendo transcription_page_108.jpg', 'Mendo transcription_page_109.jpg', 'Mendo transcription_page_11.jpg', 'Mendo transcription_page_110.jpg', 'Mendo transcription_page_111.jpg', 'Mendo transcription_page_112.jpg', 'Mendo transcription_page_113.jpg', 'Mendo transcription_page_114.jpg', 'Mendo transcription_page_116.jpg', 'Mendo transcription_page_117.jpg', 'Mendo transcription_page_118.jpg', 'Mendo transcription_page_119.jpg', 'Mendo transcription_page_120.jpg', 'Mendo transcription_page_121.jpg', 'Mendo transcription_page_122.jpg', 'Mendo transcription_page_124.jpg', 'Mendo transcription_page_125.jpg', 'Mendo transcription_page_126.jpg', 'Mendo transcription_page_127.jpg', 'Mendo transcription_page_128.jpg', 'Mendo transcription_page_129.jpg', 'Mendo transcription_page_13.jpg', 'Mendo transcription_page_130.jpg', 'Mendo transcription_page_131.jpg', 'Mendo transcription_page_132.jpg', 'Mendo transcription_page_133.jpg', 'Mendo transcription_page_134.jpg', 'Mendo transcription_page_135.jpg', 'Mendo transcription_page_136.jpg', 'Mendo transcription_page_137.jpg', 'Mendo transcription_page_138.jpg', 'Mendo transcription_page_139.jpg', 'Mendo transcription_page_14.jpg', 'Mendo transcription_page_140.jpg', 'Mendo transcription_page_142.jpg', 'Mendo transcription_page_143.jpg', 'Mendo transcription_page_144.jpg', 'Mendo transcription_page_145.jpg', 'Mendo transcription_page_146.jpg', 'Mendo transcription_page_147.jpg', 'Mendo transcription_page_148.jpg', 'Mendo transcription_page_149.jpg', 'Mendo transcription_page_15.jpg', 'Mendo transcription_page_150.jpg', 'Mendo transcription_page_151.jpg', 'Mendo transcription_page_152.jpg', 'Mendo transcription_page_153.jpg', 'Mendo transcription_page_154.jpg', 'Mendo transcription_page_155.jpg', 'Mendo transcription_page_156.jpg', 'Mendo transcription_page_16.jpg', 'Mendo transcription_page_17.jpg', 'Mendo transcription_page_18.jpg', 'Mendo transcription_page_19.jpg', 'Mendo transcription_page_2.jpg', 'Mendo transcription_page_20.jpg', 'Mendo transcription_page_21.jpg', 'Mendo transcription_page_22.jpg', 'Mendo transcription_page_23.jpg', 'Mendo transcription_page_24.jpg', 'Mendo transcription_page_26.jpg', 'Mendo transcription_page_27.jpg', 'Mendo transcription_page_28.jpg', 'Mendo transcription_page_29.jpg', 'Mendo transcription_page_3.jpg', 'Mendo transcription_page_30.jpg', 'Mendo transcription_page_31.jpg', 'Mendo transcription_page_32.jpg', 'Mendo transcription_page_33.jpg', 'Mendo transcription_page_34.jpg', 'Mendo transcription_page_35.jpg', 'Mendo transcription_page_37.jpg', 'Mendo transcription_page_38.jpg', 'Mendo transcription_page_39.jpg', 'Mendo transcription_page_4.jpg', 'Mendo transcription_page_41.jpg', 'Mendo transcription_page_42.jpg', 'Mendo transcription_page_43.jpg', 'Mendo transcription_page_44.jpg', 'Mendo transcription_page_45.jpg', 'Mendo transcription_page_46.jpg', 'Mendo transcription_page_48.jpg', 'Mendo transcription_page_49.jpg', 'Mendo transcription_page_5.jpg', 'Mendo transcription_page_50.jpg', 'Mendo transcription_page_51.jpg', 'Mendo transcription_page_52.jpg', 'Mendo transcription_page_53.jpg', 'Mendo transcription_page_54.jpg', 'Mendo transcription_page_55.jpg', 'Mendo transcription_page_56.jpg', 'Mendo transcription_page_57.jpg', 'Mendo transcription_page_58.jpg', 'Mendo transcription_page_59.jpg', 'Mendo transcription_page_6.jpg', 'Mendo transcription_page_60.jpg', 'Mendo transcription_page_61.jpg', 'Mendo transcription_page_62.jpg', 'Mendo transcription_page_63.jpg', 'Mendo transcription_page_64.jpg', 'Mendo transcription_page_65.jpg', 'Mendo transcription_page_66.jpg', 'Mendo transcription_page_67.jpg', 'Mendo transcription_page_68.jpg', 'Mendo transcription_page_69.jpg', 'Mendo transcription_page_7.jpg', 'Mendo transcription_page_70.jpg', 'Mendo transcription_page_71.jpg', 'Mendo transcription_page_72.jpg', 'Mendo transcription_page_73.jpg', 'Mendo transcription_page_74.jpg', 'Mendo transcription_page_75.jpg', 'Mendo transcription_page_77.jpg', 'Mendo transcription_page_78.jpg', 'Mendo transcription_page_79.jpg', 'Mendo transcription_page_8.jpg', 'Mendo transcription_page_80.jpg', 'Mendo transcription_page_81.jpg', 'Mendo transcription_page_82.jpg', 'Mendo transcription_page_83.jpg', 'Mendo transcription_page_84.jpg', 'Mendo transcription_page_85.jpg', 'Mendo transcription_page_86.jpg', 'Mendo transcription_page_87.jpg', 'Mendo transcription_page_88.jpg', 'Mendo transcription_page_89.jpg', 'Mendo transcription_page_9.jpg', 'Mendo transcription_page_90.jpg', 'Mendo transcription_page_91.jpg', 'Mendo transcription_page_92.jpg', 'Mendo transcription_page_93.jpg', 'Mendo transcription_page_94.jpg', 'Mendo transcription_page_95.jpg', 'Mendo transcription_page_96.jpg', 'Mendo transcription_page_97.jpg', 'Mendo transcription_page_98.jpg', 'Mendo transcription_page_99.jpg', 'PORCONES.228.35 1636 transcription_page_1.jpg', 'PORCONES.228.35 1636 transcription_page_10.jpg', 'PORCONES.228.35 1636 transcription_page_2.jpg', 'PORCONES.228.35 1636 transcription_page_3.jpg', 'PORCONES.228.35 1636 transcription_page_4.jpg', 'PORCONES.228.35 1636 transcription_page_5.jpg', 'PORCONES.228.35 1636 transcription_page_6.jpg', 'PORCONES.228.35 1636 transcription_page_7.jpg', 'PORCONES.228.35 1636 transcription_page_8.jpg', 'PORCONES.228.35 1636 transcription_page_9.jpg', 'Paredes transcription_page_1.jpg', 'Paredes transcription_page_100.jpg', 'Paredes transcription_page_101.jpg', 'Paredes transcription_page_102.jpg', 'Paredes transcription_page_103.jpg', 'Paredes transcription_page_104.jpg', 'Paredes transcription_page_105.jpg', 'Paredes transcription_page_106.jpg', 'Paredes transcription_page_13.jpg', 'Paredes transcription_page_14.jpg', 'Paredes transcription_page_15.jpg', 'Paredes transcription_page_16.jpg', 'Paredes transcription_page_17.jpg', 'Paredes transcription_page_18.jpg', 'Paredes transcription_page_19.jpg', 'Paredes transcription_page_20.jpg', 'Paredes transcription_page_21.jpg', 'Paredes transcription_page_22.jpg', 'Paredes transcription_page_23.jpg', 'Paredes transcription_page_24.jpg', 'Paredes transcription_page_26.jpg', 'Paredes transcription_page_28.jpg', 'Paredes transcription_page_29.jpg', 'Paredes transcription_page_3.jpg', 'Paredes transcription_page_30.jpg', 'Paredes transcription_page_31.jpg', 'Paredes transcription_page_32.jpg', 'Paredes transcription_page_33.jpg', 'Paredes transcription_page_34.jpg', 'Paredes transcription_page_35.jpg', 'Paredes transcription_page_36.jpg', 'Paredes transcription_page_37.jpg', 'Paredes transcription_page_38.jpg', 'Paredes transcription_page_39.jpg', 'Paredes transcription_page_40.jpg', 'Paredes transcription_page_41.jpg', 'Paredes transcription_page_42.jpg', 'Paredes transcription_page_43.jpg', 'Paredes transcription_page_44.jpg', 'Paredes transcription_page_45.jpg', 'Paredes transcription_page_46.jpg', 'Paredes transcription_page_47.jpg', 'Paredes transcription_page_48.jpg', 'Paredes transcription_page_5.jpg', 'Paredes transcription_page_50.jpg', 'Paredes transcription_page_52.jpg', 'Paredes transcription_page_53.jpg', 'Paredes transcription_page_54.jpg', 'Paredes transcription_page_55.jpg', 'Paredes transcription_page_57.jpg', 'Paredes transcription_page_58.jpg', 'Paredes transcription_page_59.jpg', 'Paredes transcription_page_6.jpg', 'Paredes transcription_page_60.jpg', 'Paredes transcription_page_61.jpg', 'Paredes transcription_page_62.jpg', 'Paredes transcription_page_63.jpg', 'Paredes transcription_page_64.jpg', 'Paredes transcription_page_65.jpg', 'Paredes transcription_page_67.jpg', 'Paredes transcription_page_69.jpg', 'Paredes transcription_page_70.jpg', 'Paredes transcription_page_71.jpg', 'Paredes transcription_page_72.jpg', 'Paredes transcription_page_73.jpg', 'Paredes transcription_page_74.jpg', 'Paredes transcription_page_75.jpg', 'Paredes transcription_page_76.jpg', 'Paredes transcription_page_77.jpg', 'Paredes transcription_page_78.jpg', 'Paredes transcription_page_79.jpg', 'Paredes transcription_page_80.jpg', 'Paredes transcription_page_81.jpg', 'Paredes transcription_page_82.jpg', 'Paredes transcription_page_83.jpg', 'Paredes transcription_page_84.jpg', 'Paredes transcription_page_85.jpg', 'Paredes transcription_page_86.jpg', 'Paredes transcription_page_87.jpg', 'Paredes transcription_page_88.jpg', 'Paredes transcription_page_89.jpg', 'Paredes transcription_page_90.jpg', 'Paredes transcription_page_91.jpg', 'Paredes transcription_page_92.jpg', 'Paredes transcription_page_93.jpg', 'Paredes transcription_page_94.jpg', 'Paredes transcription_page_95.jpg', 'Paredes transcription_page_96.jpg', 'Paredes transcription_page_97.jpg', 'Paredes transcription_page_98.jpg', 'Paredes transcription_page_99.jpg']\n",
            "Found text files: ['Buendia transcription_page_1.txt', 'Buendia transcription_page_10.txt', 'Buendia transcription_page_2.txt', 'Buendia transcription_page_3.txt', 'Buendia transcription_page_4.txt', 'Buendia transcription_page_5.txt', 'Buendia transcription_page_6.txt', 'Buendia transcription_page_7.txt', 'Buendia transcription_page_8.txt', 'Buendia transcription_page_9.txt', 'Constituciones sinodales transcription_page_1.txt', 'Constituciones sinodales transcription_page_10.txt', 'Constituciones sinodales transcription_page_11.txt', 'Constituciones sinodales transcription_page_2.txt', 'Constituciones sinodales transcription_page_3.txt', 'Constituciones sinodales transcription_page_4.txt', 'Constituciones sinodales transcription_page_5.txt', 'Constituciones sinodales transcription_page_6.txt', 'Constituciones sinodales transcription_page_7.txt', 'Constituciones sinodales transcription_page_8.txt', 'Constituciones sinodales transcription_page_9.txt', 'Ezcaray transcription_page_1.txt', 'Ezcaray transcription_page_2.txt', 'Ezcaray transcription_page_3.txt', 'Ezcaray transcription_page_4.txt', 'Ezcaray transcription_page_5.txt', 'Ezcaray transcription_page_6.txt', 'Ezcaray transcription_page_7.txt', 'Ezcaray transcription_page_8.txt', 'Mendo transcription_page_1.txt', 'Mendo transcription_page_10.txt', 'Mendo transcription_page_100.txt', 'Mendo transcription_page_101.txt', 'Mendo transcription_page_102.txt', 'Mendo transcription_page_103.txt', 'Mendo transcription_page_104.txt', 'Mendo transcription_page_105.txt', 'Mendo transcription_page_106.txt', 'Mendo transcription_page_107.txt', 'Mendo transcription_page_108.txt', 'Mendo transcription_page_109.txt', 'Mendo transcription_page_11.txt', 'Mendo transcription_page_110.txt', 'Mendo transcription_page_111.txt', 'Mendo transcription_page_112.txt', 'Mendo transcription_page_113.txt', 'Mendo transcription_page_114.txt', 'Mendo transcription_page_116.txt', 'Mendo transcription_page_117.txt', 'Mendo transcription_page_118.txt', 'Mendo transcription_page_119.txt', 'Mendo transcription_page_120.txt', 'Mendo transcription_page_121.txt', 'Mendo transcription_page_122.txt', 'Mendo transcription_page_124.txt', 'Mendo transcription_page_125.txt', 'Mendo transcription_page_126.txt', 'Mendo transcription_page_127.txt', 'Mendo transcription_page_128.txt', 'Mendo transcription_page_129.txt', 'Mendo transcription_page_13.txt', 'Mendo transcription_page_130.txt', 'Mendo transcription_page_131.txt', 'Mendo transcription_page_132.txt', 'Mendo transcription_page_133.txt', 'Mendo transcription_page_134.txt', 'Mendo transcription_page_135.txt', 'Mendo transcription_page_136.txt', 'Mendo transcription_page_137.txt', 'Mendo transcription_page_138.txt', 'Mendo transcription_page_139.txt', 'Mendo transcription_page_14.txt', 'Mendo transcription_page_140.txt', 'Mendo transcription_page_142.txt', 'Mendo transcription_page_143.txt', 'Mendo transcription_page_144.txt', 'Mendo transcription_page_145.txt', 'Mendo transcription_page_146.txt', 'Mendo transcription_page_147.txt', 'Mendo transcription_page_148.txt', 'Mendo transcription_page_149.txt', 'Mendo transcription_page_15.txt', 'Mendo transcription_page_150.txt', 'Mendo transcription_page_151.txt', 'Mendo transcription_page_152.txt', 'Mendo transcription_page_153.txt', 'Mendo transcription_page_154.txt', 'Mendo transcription_page_155.txt', 'Mendo transcription_page_156.txt', 'Mendo transcription_page_16.txt', 'Mendo transcription_page_17.txt', 'Mendo transcription_page_18.txt', 'Mendo transcription_page_19.txt', 'Mendo transcription_page_2.txt', 'Mendo transcription_page_20.txt', 'Mendo transcription_page_21.txt', 'Mendo transcription_page_22.txt', 'Mendo transcription_page_23.txt', 'Mendo transcription_page_24.txt', 'Mendo transcription_page_26.txt', 'Mendo transcription_page_27.txt', 'Mendo transcription_page_28.txt', 'Mendo transcription_page_29.txt', 'Mendo transcription_page_3.txt', 'Mendo transcription_page_30.txt', 'Mendo transcription_page_31.txt', 'Mendo transcription_page_32.txt', 'Mendo transcription_page_33.txt', 'Mendo transcription_page_34.txt', 'Mendo transcription_page_35.txt', 'Mendo transcription_page_37.txt', 'Mendo transcription_page_38.txt', 'Mendo transcription_page_39.txt', 'Mendo transcription_page_4.txt', 'Mendo transcription_page_41.txt', 'Mendo transcription_page_42.txt', 'Mendo transcription_page_43.txt', 'Mendo transcription_page_44.txt', 'Mendo transcription_page_45.txt', 'Mendo transcription_page_46.txt', 'Mendo transcription_page_48.txt', 'Mendo transcription_page_49.txt', 'Mendo transcription_page_5.txt', 'Mendo transcription_page_50.txt', 'Mendo transcription_page_51.txt', 'Mendo transcription_page_52.txt', 'Mendo transcription_page_53.txt', 'Mendo transcription_page_54.txt', 'Mendo transcription_page_55.txt', 'Mendo transcription_page_56.txt', 'Mendo transcription_page_57.txt', 'Mendo transcription_page_58.txt', 'Mendo transcription_page_59.txt', 'Mendo transcription_page_6.txt', 'Mendo transcription_page_60.txt', 'Mendo transcription_page_61.txt', 'Mendo transcription_page_62.txt', 'Mendo transcription_page_63.txt', 'Mendo transcription_page_64.txt', 'Mendo transcription_page_65.txt', 'Mendo transcription_page_66.txt', 'Mendo transcription_page_67.txt', 'Mendo transcription_page_68.txt', 'Mendo transcription_page_69.txt', 'Mendo transcription_page_7.txt', 'Mendo transcription_page_70.txt', 'Mendo transcription_page_71.txt', 'Mendo transcription_page_72.txt', 'Mendo transcription_page_73.txt', 'Mendo transcription_page_74.txt', 'Mendo transcription_page_75.txt', 'Mendo transcription_page_77.txt', 'Mendo transcription_page_78.txt', 'Mendo transcription_page_79.txt', 'Mendo transcription_page_8.txt', 'Mendo transcription_page_80.txt', 'Mendo transcription_page_81.txt', 'Mendo transcription_page_82.txt', 'Mendo transcription_page_83.txt', 'Mendo transcription_page_84.txt', 'Mendo transcription_page_85.txt', 'Mendo transcription_page_86.txt', 'Mendo transcription_page_87.txt', 'Mendo transcription_page_88.txt', 'Mendo transcription_page_89.txt', 'Mendo transcription_page_9.txt', 'Mendo transcription_page_90.txt', 'Mendo transcription_page_91.txt', 'Mendo transcription_page_92.txt', 'Mendo transcription_page_93.txt', 'Mendo transcription_page_94.txt', 'Mendo transcription_page_95.txt', 'Mendo transcription_page_96.txt', 'Mendo transcription_page_97.txt', 'Mendo transcription_page_98.txt', 'Mendo transcription_page_99.txt', 'PORCONES.228.35 1636 transcription_page_1.txt', 'PORCONES.228.35 1636 transcription_page_10.txt', 'PORCONES.228.35 1636 transcription_page_2.txt', 'PORCONES.228.35 1636 transcription_page_3.txt', 'PORCONES.228.35 1636 transcription_page_4.txt', 'PORCONES.228.35 1636 transcription_page_5.txt', 'PORCONES.228.35 1636 transcription_page_6.txt', 'PORCONES.228.35 1636 transcription_page_7.txt', 'PORCONES.228.35 1636 transcription_page_8.txt', 'PORCONES.228.35 1636 transcription_page_9.txt', 'Paredes transcription_page_1.txt', 'Paredes transcription_page_100.txt', 'Paredes transcription_page_101.txt', 'Paredes transcription_page_102.txt', 'Paredes transcription_page_103.txt', 'Paredes transcription_page_104.txt', 'Paredes transcription_page_105.txt', 'Paredes transcription_page_106.txt', 'Paredes transcription_page_13.txt', 'Paredes transcription_page_14.txt', 'Paredes transcription_page_15.txt', 'Paredes transcription_page_16.txt', 'Paredes transcription_page_17.txt', 'Paredes transcription_page_18.txt', 'Paredes transcription_page_19.txt', 'Paredes transcription_page_20.txt', 'Paredes transcription_page_21.txt', 'Paredes transcription_page_22.txt', 'Paredes transcription_page_23.txt', 'Paredes transcription_page_24.txt', 'Paredes transcription_page_26.txt', 'Paredes transcription_page_28.txt', 'Paredes transcription_page_29.txt', 'Paredes transcription_page_3.txt', 'Paredes transcription_page_30.txt', 'Paredes transcription_page_31.txt', 'Paredes transcription_page_32.txt', 'Paredes transcription_page_33.txt', 'Paredes transcription_page_34.txt', 'Paredes transcription_page_35.txt', 'Paredes transcription_page_36.txt', 'Paredes transcription_page_37.txt', 'Paredes transcription_page_38.txt', 'Paredes transcription_page_39.txt', 'Paredes transcription_page_40.txt', 'Paredes transcription_page_41.txt', 'Paredes transcription_page_42.txt', 'Paredes transcription_page_43.txt', 'Paredes transcription_page_44.txt', 'Paredes transcription_page_45.txt', 'Paredes transcription_page_46.txt', 'Paredes transcription_page_47.txt', 'Paredes transcription_page_48.txt', 'Paredes transcription_page_5.txt', 'Paredes transcription_page_50.txt', 'Paredes transcription_page_52.txt', 'Paredes transcription_page_53.txt', 'Paredes transcription_page_54.txt', 'Paredes transcription_page_55.txt', 'Paredes transcription_page_57.txt', 'Paredes transcription_page_58.txt', 'Paredes transcription_page_59.txt', 'Paredes transcription_page_6.txt', 'Paredes transcription_page_60.txt', 'Paredes transcription_page_61.txt', 'Paredes transcription_page_62.txt', 'Paredes transcription_page_63.txt', 'Paredes transcription_page_64.txt', 'Paredes transcription_page_65.txt', 'Paredes transcription_page_67.txt', 'Paredes transcription_page_69.txt', 'Paredes transcription_page_70.txt', 'Paredes transcription_page_71.txt', 'Paredes transcription_page_72.txt', 'Paredes transcription_page_73.txt', 'Paredes transcription_page_74.txt', 'Paredes transcription_page_75.txt', 'Paredes transcription_page_76.txt', 'Paredes transcription_page_77.txt', 'Paredes transcription_page_78.txt', 'Paredes transcription_page_79.txt', 'Paredes transcription_page_80.txt', 'Paredes transcription_page_81.txt', 'Paredes transcription_page_82.txt', 'Paredes transcription_page_83.txt', 'Paredes transcription_page_84.txt', 'Paredes transcription_page_85.txt', 'Paredes transcription_page_86.txt', 'Paredes transcription_page_87.txt', 'Paredes transcription_page_88.txt', 'Paredes transcription_page_89.txt', 'Paredes transcription_page_90.txt', 'Paredes transcription_page_91.txt', 'Paredes transcription_page_92.txt', 'Paredes transcription_page_93.txt', 'Paredes transcription_page_94.txt', 'Paredes transcription_page_95.txt', 'Paredes transcription_page_96.txt', 'Paredes transcription_page_97.txt', 'Paredes transcription_page_98.txt', 'Paredes transcription_page_99.txt']\n",
            "Starting training of the hybrid CNN+Transformer model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/110], Batch [10/35], Loss: 1.3198\n",
            "Epoch [1/110], Batch [20/35], Loss: 2.1669\n",
            "Epoch [1/110], Batch [30/35], Loss: 1.9043\n",
            "Epoch [1/110] Average Loss: 1.6545\n",
            "\n",
            "Epoch [2/110], Batch [10/35], Loss: 2.3591\n",
            "Epoch [2/110], Batch [20/35], Loss: 2.3572\n",
            "Epoch [2/110], Batch [30/35], Loss: 2.7690\n",
            "Epoch [2/110] Average Loss: 2.6703\n",
            "\n",
            "Epoch [3/110], Batch [10/35], Loss: 3.1347\n",
            "Epoch [3/110], Batch [20/35], Loss: 2.6242\n",
            "Epoch [3/110], Batch [30/35], Loss: 2.4918\n",
            "Epoch [3/110] Average Loss: 2.8682\n",
            "\n",
            "Epoch [4/110], Batch [10/35], Loss: 2.7173\n",
            "Epoch [4/110], Batch [20/35], Loss: 2.2975\n",
            "Epoch [4/110], Batch [30/35], Loss: 3.2894\n",
            "Epoch [4/110] Average Loss: 2.8725\n",
            "\n",
            "Epoch [5/110], Batch [10/35], Loss: 2.8424\n",
            "Epoch [5/110], Batch [20/35], Loss: 2.2399\n",
            "Epoch [5/110], Batch [30/35], Loss: 4.6711\n",
            "Epoch [5/110] Average Loss: 2.7405\n",
            "\n",
            "Epoch [6/110], Batch [10/35], Loss: 4.0364\n",
            "Epoch [6/110], Batch [20/35], Loss: 2.4451\n",
            "Epoch [6/110], Batch [30/35], Loss: 2.8147\n",
            "Epoch [6/110] Average Loss: 2.3898\n",
            "\n",
            "Epoch [7/110], Batch [10/35], Loss: 2.5552\n",
            "Epoch [7/110], Batch [20/35], Loss: 3.0007\n",
            "Epoch [7/110], Batch [30/35], Loss: 2.2934\n",
            "Epoch [7/110] Average Loss: 2.3542\n",
            "\n",
            "Epoch [8/110], Batch [10/35], Loss: 1.0731\n",
            "Epoch [8/110], Batch [20/35], Loss: 2.6985\n",
            "Epoch [8/110], Batch [30/35], Loss: 3.1983\n",
            "Epoch [8/110] Average Loss: 2.3669\n",
            "\n",
            "Epoch [9/110], Batch [10/35], Loss: 1.9444\n",
            "Epoch [9/110], Batch [20/35], Loss: 2.8144\n",
            "Epoch [9/110], Batch [30/35], Loss: 1.4703\n",
            "Epoch [9/110] Average Loss: 2.3290\n",
            "\n",
            "Epoch [10/110], Batch [10/35], Loss: 2.7702\n",
            "Epoch [10/110], Batch [20/35], Loss: 2.9214\n",
            "Epoch [10/110], Batch [30/35], Loss: 2.6873\n",
            "Epoch [10/110] Average Loss: 2.3355\n",
            "\n",
            "Epoch [11/110], Batch [10/35], Loss: 2.4646\n",
            "Epoch [11/110], Batch [20/35], Loss: 2.2272\n",
            "Epoch [11/110], Batch [30/35], Loss: 2.6161\n",
            "Epoch [11/110] Average Loss: 2.3226\n",
            "\n",
            "Epoch [12/110], Batch [10/35], Loss: 1.7167\n",
            "Epoch [12/110], Batch [20/35], Loss: 2.1979\n",
            "Epoch [12/110], Batch [30/35], Loss: 2.0972\n",
            "Epoch [12/110] Average Loss: 2.3169\n",
            "\n",
            "Epoch [13/110], Batch [10/35], Loss: 2.7532\n",
            "Epoch [13/110], Batch [20/35], Loss: 2.4111\n",
            "Epoch [13/110], Batch [30/35], Loss: 2.9462\n",
            "Epoch [13/110] Average Loss: 2.2989\n",
            "\n",
            "Epoch [14/110], Batch [10/35], Loss: 2.8586\n",
            "Epoch [14/110], Batch [20/35], Loss: 2.4468\n",
            "Epoch [14/110], Batch [30/35], Loss: 2.1834\n",
            "Epoch [14/110] Average Loss: 2.3048\n",
            "\n",
            "Epoch [15/110], Batch [10/35], Loss: 2.2127\n",
            "Epoch [15/110], Batch [20/35], Loss: 2.5083\n",
            "Epoch [15/110], Batch [30/35], Loss: 1.7858\n",
            "Epoch [15/110] Average Loss: 2.3035\n",
            "\n",
            "Epoch [16/110], Batch [10/35], Loss: 2.4623\n",
            "Epoch [16/110], Batch [20/35], Loss: 2.6584\n",
            "Epoch [16/110], Batch [30/35], Loss: 2.4327\n",
            "Epoch [16/110] Average Loss: 2.3182\n",
            "\n",
            "Epoch [17/110], Batch [10/35], Loss: 1.6729\n",
            "Epoch [17/110], Batch [20/35], Loss: 1.5506\n",
            "Epoch [17/110], Batch [30/35], Loss: 2.5238\n",
            "Epoch [17/110] Average Loss: 2.3029\n",
            "\n",
            "Epoch [18/110], Batch [10/35], Loss: 1.8024\n",
            "Epoch [18/110], Batch [20/35], Loss: 2.2324\n",
            "Epoch [18/110], Batch [30/35], Loss: 1.0077\n",
            "Epoch [18/110] Average Loss: 2.2834\n",
            "\n",
            "Epoch [19/110], Batch [10/35], Loss: 2.9555\n",
            "Epoch [19/110], Batch [20/35], Loss: 1.8958\n",
            "Epoch [19/110], Batch [30/35], Loss: 2.4621\n",
            "Epoch [19/110] Average Loss: 2.2874\n",
            "\n",
            "Epoch [20/110], Batch [10/35], Loss: 2.1499\n",
            "Epoch [20/110], Batch [20/35], Loss: 2.6208\n",
            "Epoch [20/110], Batch [30/35], Loss: 3.2313\n",
            "Epoch [20/110] Average Loss: 2.2775\n",
            "\n",
            "Epoch [21/110], Batch [10/35], Loss: 2.0766\n",
            "Epoch [21/110], Batch [20/35], Loss: 2.3850\n",
            "Epoch [21/110], Batch [30/35], Loss: 2.2582\n",
            "Epoch [21/110] Average Loss: 2.2502\n",
            "\n",
            "Epoch [22/110], Batch [10/35], Loss: 2.1890\n",
            "Epoch [22/110], Batch [20/35], Loss: 2.5244\n",
            "Epoch [22/110], Batch [30/35], Loss: 2.8966\n",
            "Epoch [22/110] Average Loss: 2.3391\n",
            "\n",
            "Epoch [23/110], Batch [10/35], Loss: 2.5643\n",
            "Epoch [23/110], Batch [20/35], Loss: 1.5420\n",
            "Epoch [23/110], Batch [30/35], Loss: 2.5601\n",
            "Epoch [23/110] Average Loss: 2.4520\n",
            "\n",
            "Epoch [24/110], Batch [10/35], Loss: 1.9692\n",
            "Epoch [24/110], Batch [20/35], Loss: 2.8897\n",
            "Epoch [24/110], Batch [30/35], Loss: 2.1864\n",
            "Epoch [24/110] Average Loss: 2.2702\n",
            "\n",
            "Epoch [25/110], Batch [10/35], Loss: 1.7623\n",
            "Epoch [25/110], Batch [20/35], Loss: 2.4834\n",
            "Epoch [25/110], Batch [30/35], Loss: 2.3219\n",
            "Epoch [25/110] Average Loss: 2.2652\n",
            "\n",
            "Epoch [26/110], Batch [10/35], Loss: 2.4484\n",
            "Epoch [26/110], Batch [20/35], Loss: 2.5614\n",
            "Epoch [26/110], Batch [30/35], Loss: 2.1343\n",
            "Epoch [26/110] Average Loss: 2.2162\n",
            "\n",
            "Epoch [27/110], Batch [10/35], Loss: 1.7120\n",
            "Epoch [27/110], Batch [20/35], Loss: 2.8620\n",
            "Epoch [27/110], Batch [30/35], Loss: 2.8091\n",
            "Epoch [27/110] Average Loss: 2.3490\n",
            "\n",
            "Epoch [28/110], Batch [10/35], Loss: 1.8147\n",
            "Epoch [28/110], Batch [20/35], Loss: 2.2341\n",
            "Epoch [28/110], Batch [30/35], Loss: 2.1129\n",
            "Epoch [28/110] Average Loss: 2.2605\n",
            "\n",
            "Epoch [29/110], Batch [10/35], Loss: 1.9928\n",
            "Epoch [29/110], Batch [20/35], Loss: 2.5412\n",
            "Epoch [29/110], Batch [30/35], Loss: 1.2823\n",
            "Epoch [29/110] Average Loss: 2.2371\n",
            "\n",
            "Epoch [30/110], Batch [10/35], Loss: 2.1318\n",
            "Epoch [30/110], Batch [20/35], Loss: 2.1967\n",
            "Epoch [30/110], Batch [30/35], Loss: 1.8786\n",
            "Epoch [30/110] Average Loss: 2.2310\n",
            "\n",
            "Epoch [31/110], Batch [10/35], Loss: 2.5921\n",
            "Epoch [31/110], Batch [20/35], Loss: 0.8869\n",
            "Epoch [31/110], Batch [30/35], Loss: 2.1577\n",
            "Epoch [31/110] Average Loss: 2.2154\n",
            "\n",
            "Epoch [32/110], Batch [10/35], Loss: 2.3136\n",
            "Epoch [32/110], Batch [20/35], Loss: 1.8600\n",
            "Epoch [32/110], Batch [30/35], Loss: 2.6379\n",
            "Epoch [32/110] Average Loss: 2.2140\n",
            "\n",
            "Epoch [33/110], Batch [10/35], Loss: 1.6433\n",
            "Epoch [33/110], Batch [20/35], Loss: 1.8491\n",
            "Epoch [33/110], Batch [30/35], Loss: 1.7833\n",
            "Epoch [33/110] Average Loss: 2.2024\n",
            "\n",
            "Epoch [34/110], Batch [10/35], Loss: 2.6045\n",
            "Epoch [34/110], Batch [20/35], Loss: 2.6195\n",
            "Epoch [34/110], Batch [30/35], Loss: 1.1107\n",
            "Epoch [34/110] Average Loss: 2.1908\n",
            "\n",
            "Epoch [35/110], Batch [10/35], Loss: 2.5428\n",
            "Epoch [35/110], Batch [20/35], Loss: 1.8317\n",
            "Epoch [35/110], Batch [30/35], Loss: 1.8138\n",
            "Epoch [35/110] Average Loss: 2.1938\n",
            "\n",
            "Epoch [36/110], Batch [10/35], Loss: 2.0659\n",
            "Epoch [36/110], Batch [20/35], Loss: 2.5853\n",
            "Epoch [36/110], Batch [30/35], Loss: 2.4676\n",
            "Epoch [36/110] Average Loss: 2.2070\n",
            "\n",
            "Epoch [37/110], Batch [10/35], Loss: 1.2867\n",
            "Epoch [37/110], Batch [20/35], Loss: 2.1069\n",
            "Epoch [37/110], Batch [30/35], Loss: 1.3763\n",
            "Epoch [37/110] Average Loss: 2.2252\n",
            "\n",
            "Epoch [38/110], Batch [10/35], Loss: 2.5337\n",
            "Epoch [38/110], Batch [20/35], Loss: 2.1640\n",
            "Epoch [38/110], Batch [30/35], Loss: 2.8302\n",
            "Epoch [38/110] Average Loss: 2.2073\n",
            "\n",
            "Epoch [39/110], Batch [10/35], Loss: 2.3087\n",
            "Epoch [39/110], Batch [20/35], Loss: 1.8376\n",
            "Epoch [39/110], Batch [30/35], Loss: 2.2646\n",
            "Epoch [39/110] Average Loss: 2.1708\n",
            "\n",
            "Epoch [40/110], Batch [10/35], Loss: 2.1860\n",
            "Epoch [40/110], Batch [20/35], Loss: 2.5102\n",
            "Epoch [40/110], Batch [30/35], Loss: 1.8337\n",
            "Epoch [40/110] Average Loss: 2.1653\n",
            "\n",
            "Epoch [41/110], Batch [10/35], Loss: 2.9214\n",
            "Epoch [41/110], Batch [20/35], Loss: 2.4254\n",
            "Epoch [41/110], Batch [30/35], Loss: 1.6355\n",
            "Epoch [41/110] Average Loss: 2.1871\n",
            "\n",
            "Epoch [42/110], Batch [10/35], Loss: 3.0051\n",
            "Epoch [42/110], Batch [20/35], Loss: 2.5380\n",
            "Epoch [42/110], Batch [30/35], Loss: 2.4127\n",
            "Epoch [42/110] Average Loss: 2.1555\n",
            "\n",
            "Epoch [43/110], Batch [10/35], Loss: 2.6117\n",
            "Epoch [43/110], Batch [20/35], Loss: 1.7921\n",
            "Epoch [43/110], Batch [30/35], Loss: 3.0105\n",
            "Epoch [43/110] Average Loss: 2.1686\n",
            "\n",
            "Epoch [44/110], Batch [10/35], Loss: 2.1413\n",
            "Epoch [44/110], Batch [20/35], Loss: 1.8866\n",
            "Epoch [44/110], Batch [30/35], Loss: 1.9767\n",
            "Epoch [44/110] Average Loss: 2.1545\n",
            "\n",
            "Epoch [45/110], Batch [10/35], Loss: 1.9710\n",
            "Epoch [45/110], Batch [20/35], Loss: 1.6486\n",
            "Epoch [45/110], Batch [30/35], Loss: 2.1409\n",
            "Epoch [45/110] Average Loss: 2.1418\n",
            "\n",
            "Epoch [46/110], Batch [10/35], Loss: 2.4634\n",
            "Epoch [46/110], Batch [20/35], Loss: 2.1855\n",
            "Epoch [46/110], Batch [30/35], Loss: 1.9893\n",
            "Epoch [46/110] Average Loss: 2.1391\n",
            "\n",
            "Epoch [47/110], Batch [10/35], Loss: 2.1436\n",
            "Epoch [47/110], Batch [20/35], Loss: 2.5585\n",
            "Epoch [47/110], Batch [30/35], Loss: 2.5607\n",
            "Epoch [47/110] Average Loss: 2.1470\n",
            "\n",
            "Epoch [48/110], Batch [10/35], Loss: 2.7510\n",
            "Epoch [48/110], Batch [20/35], Loss: 1.2785\n",
            "Epoch [48/110], Batch [30/35], Loss: 2.0419\n",
            "Epoch [48/110] Average Loss: 2.1254\n",
            "\n",
            "Epoch [49/110], Batch [10/35], Loss: 1.8750\n",
            "Epoch [49/110], Batch [20/35], Loss: 2.5101\n",
            "Epoch [49/110], Batch [30/35], Loss: 1.8888\n",
            "Epoch [49/110] Average Loss: 2.1136\n",
            "\n",
            "Epoch [50/110], Batch [10/35], Loss: 2.0801\n",
            "Epoch [50/110], Batch [20/35], Loss: 2.1279\n",
            "Epoch [50/110], Batch [30/35], Loss: 1.8253\n",
            "Epoch [50/110] Average Loss: 2.0904\n",
            "\n",
            "Epoch [51/110], Batch [10/35], Loss: 2.1443\n",
            "Epoch [51/110], Batch [20/35], Loss: 2.2566\n",
            "Epoch [51/110], Batch [30/35], Loss: 2.8350\n",
            "Epoch [51/110] Average Loss: 2.0959\n",
            "\n",
            "Epoch [52/110], Batch [10/35], Loss: 1.8460\n",
            "Epoch [52/110], Batch [20/35], Loss: 1.8214\n",
            "Epoch [52/110], Batch [30/35], Loss: 2.4753\n",
            "Epoch [52/110] Average Loss: 2.0989\n",
            "\n",
            "Epoch [53/110], Batch [10/35], Loss: 2.0414\n",
            "Epoch [53/110], Batch [20/35], Loss: 2.0623\n",
            "Epoch [53/110], Batch [30/35], Loss: 1.8009\n",
            "Epoch [53/110] Average Loss: 2.0773\n",
            "\n",
            "Epoch [54/110], Batch [10/35], Loss: 1.7609\n",
            "Epoch [54/110], Batch [20/35], Loss: 2.3069\n",
            "Epoch [54/110], Batch [30/35], Loss: 2.0513\n",
            "Epoch [54/110] Average Loss: 2.0388\n",
            "\n",
            "Epoch [55/110], Batch [10/35], Loss: 2.8993\n",
            "Epoch [55/110], Batch [20/35], Loss: 2.0753\n",
            "Epoch [55/110], Batch [30/35], Loss: 2.5377\n",
            "Epoch [55/110] Average Loss: 2.0644\n",
            "\n",
            "Epoch [56/110], Batch [10/35], Loss: 1.7770\n",
            "Epoch [56/110], Batch [20/35], Loss: 2.2573\n",
            "Epoch [56/110], Batch [30/35], Loss: 2.3350\n",
            "Epoch [56/110] Average Loss: 2.0553\n",
            "\n",
            "Epoch [57/110], Batch [10/35], Loss: 2.0414\n",
            "Epoch [57/110], Batch [20/35], Loss: 1.2380\n",
            "Epoch [57/110], Batch [30/35], Loss: 1.6747\n",
            "Epoch [57/110] Average Loss: 2.0211\n",
            "\n",
            "Epoch [58/110], Batch [10/35], Loss: 0.9571\n",
            "Epoch [58/110], Batch [20/35], Loss: 1.6399\n",
            "Epoch [58/110], Batch [30/35], Loss: 2.1313\n",
            "Epoch [58/110] Average Loss: 1.9916\n",
            "\n",
            "Epoch [59/110], Batch [10/35], Loss: 1.1725\n",
            "Epoch [59/110], Batch [20/35], Loss: 2.0149\n",
            "Epoch [59/110], Batch [30/35], Loss: 1.8259\n",
            "Epoch [59/110] Average Loss: 1.9287\n",
            "\n",
            "Epoch [60/110], Batch [10/35], Loss: 1.3168\n",
            "Epoch [60/110], Batch [20/35], Loss: 1.3138\n",
            "Epoch [60/110], Batch [30/35], Loss: 2.0075\n",
            "Epoch [60/110] Average Loss: 1.9008\n",
            "\n",
            "Epoch [61/110], Batch [10/35], Loss: 1.6626\n",
            "Epoch [61/110], Batch [20/35], Loss: 1.2847\n",
            "Epoch [61/110], Batch [30/35], Loss: 2.1187\n",
            "Epoch [61/110] Average Loss: 1.9453\n",
            "\n",
            "Epoch [62/110], Batch [10/35], Loss: 2.2124\n",
            "Epoch [62/110], Batch [20/35], Loss: 2.1536\n",
            "Epoch [62/110], Batch [30/35], Loss: 1.3182\n",
            "Epoch [62/110] Average Loss: 1.8891\n",
            "\n",
            "Epoch [63/110], Batch [10/35], Loss: 2.3383\n",
            "Epoch [63/110], Batch [20/35], Loss: 1.1441\n",
            "Epoch [63/110], Batch [30/35], Loss: 0.7607\n",
            "Epoch [63/110] Average Loss: 1.7570\n",
            "\n",
            "Epoch [64/110], Batch [10/35], Loss: 1.7788\n",
            "Epoch [64/110], Batch [20/35], Loss: 1.3121\n",
            "Epoch [64/110], Batch [30/35], Loss: 1.6891\n",
            "Epoch [64/110] Average Loss: 1.6656\n",
            "\n",
            "Epoch [65/110], Batch [10/35], Loss: 1.5270\n",
            "Epoch [65/110], Batch [20/35], Loss: 1.0857\n",
            "Epoch [65/110], Batch [30/35], Loss: 2.0142\n",
            "Epoch [65/110] Average Loss: 1.6131\n",
            "\n",
            "Epoch [66/110], Batch [10/35], Loss: 1.2731\n",
            "Epoch [66/110], Batch [20/35], Loss: 1.1465\n",
            "Epoch [66/110], Batch [30/35], Loss: 1.4745\n",
            "Epoch [66/110] Average Loss: 1.4809\n",
            "\n",
            "Epoch [67/110], Batch [10/35], Loss: 1.0657\n",
            "Epoch [67/110], Batch [20/35], Loss: 0.6630\n",
            "Epoch [67/110], Batch [30/35], Loss: 1.1963\n",
            "Epoch [67/110] Average Loss: 1.3466\n",
            "\n",
            "Epoch [68/110], Batch [10/35], Loss: 1.3277\n",
            "Epoch [68/110], Batch [20/35], Loss: 1.2227\n",
            "Epoch [68/110], Batch [30/35], Loss: 1.3134\n",
            "Epoch [68/110] Average Loss: 1.2278\n",
            "\n",
            "Epoch [69/110], Batch [10/35], Loss: 1.4329\n",
            "Epoch [69/110], Batch [20/35], Loss: 0.9979\n",
            "Epoch [69/110], Batch [30/35], Loss: 1.5276\n",
            "Epoch [69/110] Average Loss: 1.1367\n",
            "\n",
            "Epoch [70/110], Batch [10/35], Loss: 1.1185\n",
            "Epoch [70/110], Batch [20/35], Loss: 0.9824\n",
            "Epoch [70/110], Batch [30/35], Loss: 1.1675\n",
            "Epoch [70/110] Average Loss: 1.0317\n",
            "\n",
            "Epoch [71/110], Batch [10/35], Loss: 0.8591\n",
            "Epoch [71/110], Batch [20/35], Loss: 1.1611\n",
            "Epoch [71/110], Batch [30/35], Loss: 1.3608\n",
            "Epoch [71/110] Average Loss: 0.9649\n",
            "\n",
            "Epoch [72/110], Batch [10/35], Loss: 0.4362\n",
            "Epoch [72/110], Batch [20/35], Loss: 0.7729\n",
            "Epoch [72/110], Batch [30/35], Loss: 1.2129\n",
            "Epoch [72/110] Average Loss: 0.8675\n",
            "\n",
            "Epoch [73/110], Batch [10/35], Loss: 1.0635\n",
            "Epoch [73/110], Batch [20/35], Loss: 0.5614\n",
            "Epoch [73/110], Batch [30/35], Loss: 0.4180\n",
            "Epoch [73/110] Average Loss: 0.7664\n",
            "\n",
            "Epoch [74/110], Batch [10/35], Loss: 0.9781\n",
            "Epoch [74/110], Batch [20/35], Loss: 0.8654\n",
            "Epoch [74/110], Batch [30/35], Loss: 0.5957\n",
            "Epoch [74/110] Average Loss: 0.7815\n",
            "\n",
            "Epoch [75/110], Batch [10/35], Loss: 0.5752\n",
            "Epoch [75/110], Batch [20/35], Loss: 0.7455\n",
            "Epoch [75/110], Batch [30/35], Loss: 0.6738\n",
            "Epoch [75/110] Average Loss: 0.7129\n",
            "\n",
            "Epoch [76/110], Batch [10/35], Loss: 0.5726\n",
            "Epoch [76/110], Batch [20/35], Loss: 0.3396\n",
            "Epoch [76/110], Batch [30/35], Loss: 0.5224\n",
            "Epoch [76/110] Average Loss: 0.6152\n",
            "\n",
            "Epoch [77/110], Batch [10/35], Loss: 0.1108\n",
            "Epoch [77/110], Batch [20/35], Loss: 0.3797\n",
            "Epoch [77/110], Batch [30/35], Loss: 0.6659\n",
            "Epoch [77/110] Average Loss: 0.5785\n",
            "\n",
            "Epoch [78/110], Batch [10/35], Loss: 0.6421\n",
            "Epoch [78/110], Batch [20/35], Loss: 0.5750\n",
            "Epoch [78/110], Batch [30/35], Loss: 0.4092\n",
            "Epoch [78/110] Average Loss: 0.5337\n",
            "\n",
            "Epoch [79/110], Batch [10/35], Loss: 0.5163\n",
            "Epoch [79/110], Batch [20/35], Loss: 0.6265\n",
            "Epoch [79/110], Batch [30/35], Loss: 0.3859\n",
            "Epoch [79/110] Average Loss: 0.5007\n",
            "\n",
            "Epoch [80/110], Batch [10/35], Loss: 0.5083\n",
            "Epoch [80/110], Batch [20/35], Loss: 0.3271\n",
            "Epoch [80/110], Batch [30/35], Loss: 0.2676\n",
            "Epoch [80/110] Average Loss: 0.4716\n",
            "\n",
            "Epoch [81/110], Batch [10/35], Loss: 0.5572\n",
            "Epoch [81/110], Batch [20/35], Loss: 0.5171\n",
            "Epoch [81/110], Batch [30/35], Loss: 0.4846\n",
            "Epoch [81/110] Average Loss: 0.4587\n",
            "\n",
            "Epoch [82/110], Batch [10/35], Loss: 0.2427\n",
            "Epoch [82/110], Batch [20/35], Loss: 0.3168\n",
            "Epoch [82/110], Batch [30/35], Loss: 0.2829\n",
            "Epoch [82/110] Average Loss: 0.4301\n",
            "\n",
            "Epoch [83/110], Batch [10/35], Loss: 0.5259\n",
            "Epoch [83/110], Batch [20/35], Loss: 0.3633\n",
            "Epoch [83/110], Batch [30/35], Loss: 0.4783\n",
            "Epoch [83/110] Average Loss: 0.4155\n",
            "\n",
            "Epoch [84/110], Batch [10/35], Loss: 0.5455\n",
            "Epoch [84/110], Batch [20/35], Loss: 0.4254\n",
            "Epoch [84/110], Batch [30/35], Loss: 0.5135\n",
            "Epoch [84/110] Average Loss: 0.3952\n",
            "\n",
            "Epoch [85/110], Batch [10/35], Loss: 0.4550\n",
            "Epoch [85/110], Batch [20/35], Loss: 0.3966\n",
            "Epoch [85/110], Batch [30/35], Loss: 0.3501\n",
            "Epoch [85/110] Average Loss: 0.3775\n",
            "\n",
            "Epoch [86/110], Batch [10/35], Loss: 0.3391\n",
            "Epoch [86/110], Batch [20/35], Loss: 0.3013\n",
            "Epoch [86/110], Batch [30/35], Loss: 0.1231\n",
            "Epoch [86/110] Average Loss: 0.3609\n",
            "\n",
            "Epoch [87/110], Batch [10/35], Loss: 0.2596\n",
            "Epoch [87/110], Batch [20/35], Loss: 0.3485\n",
            "Epoch [87/110], Batch [30/35], Loss: 0.3194\n",
            "Epoch [87/110] Average Loss: 0.3504\n",
            "\n",
            "Epoch [88/110], Batch [10/35], Loss: 0.2367\n",
            "Epoch [88/110], Batch [20/35], Loss: 0.2772\n",
            "Epoch [88/110], Batch [30/35], Loss: 0.2930\n",
            "Epoch [88/110] Average Loss: 0.3318\n",
            "\n",
            "Epoch [89/110], Batch [10/35], Loss: 0.4888\n",
            "Epoch [89/110], Batch [20/35], Loss: 0.4407\n",
            "Epoch [89/110], Batch [30/35], Loss: 0.3056\n",
            "Epoch [89/110] Average Loss: 0.3567\n",
            "\n",
            "Epoch [90/110], Batch [10/35], Loss: 0.4836\n",
            "Epoch [90/110], Batch [20/35], Loss: 0.5411\n",
            "Epoch [90/110], Batch [30/35], Loss: 0.1346\n",
            "Epoch [90/110] Average Loss: 0.3641\n",
            "\n",
            "Epoch [91/110], Batch [10/35], Loss: 0.3569\n",
            "Epoch [91/110], Batch [20/35], Loss: 0.3014\n",
            "Epoch [91/110], Batch [30/35], Loss: 0.1792\n",
            "Epoch [91/110] Average Loss: 0.3793\n",
            "\n",
            "Epoch [92/110], Batch [10/35], Loss: 0.3900\n",
            "Epoch [92/110], Batch [20/35], Loss: 0.3853\n",
            "Epoch [92/110], Batch [30/35], Loss: 0.3989\n",
            "Epoch [92/110] Average Loss: 0.3598\n",
            "\n",
            "Epoch [93/110], Batch [10/35], Loss: 0.3381\n",
            "Epoch [93/110], Batch [20/35], Loss: 0.3094\n",
            "Epoch [93/110], Batch [30/35], Loss: 0.4735\n",
            "Epoch [93/110] Average Loss: 0.3326\n",
            "\n",
            "Epoch [94/110], Batch [10/35], Loss: 0.3982\n",
            "Epoch [94/110], Batch [20/35], Loss: 0.2956\n",
            "Epoch [94/110], Batch [30/35], Loss: 0.3989\n",
            "Epoch [94/110] Average Loss: 0.3204\n",
            "\n",
            "Epoch [95/110], Batch [10/35], Loss: 0.3003\n",
            "Epoch [95/110], Batch [20/35], Loss: 0.2591\n",
            "Epoch [95/110], Batch [30/35], Loss: 0.2459\n",
            "Epoch [95/110] Average Loss: 0.2871\n",
            "\n",
            "Epoch [96/110], Batch [10/35], Loss: 0.1797\n",
            "Epoch [96/110], Batch [20/35], Loss: 0.1734\n",
            "Epoch [96/110], Batch [30/35], Loss: 0.1468\n",
            "Epoch [96/110] Average Loss: 0.2407\n",
            "\n",
            "Epoch [97/110], Batch [10/35], Loss: 0.1827\n",
            "Epoch [97/110], Batch [20/35], Loss: 0.1987\n",
            "Epoch [97/110], Batch [30/35], Loss: 0.2313\n",
            "Epoch [97/110] Average Loss: 0.2435\n",
            "\n",
            "Epoch [98/110], Batch [10/35], Loss: 0.3241\n",
            "Epoch [98/110], Batch [20/35], Loss: 0.1849\n",
            "Epoch [98/110], Batch [30/35], Loss: 0.2104\n",
            "Epoch [98/110] Average Loss: 0.2392\n",
            "\n",
            "Epoch [99/110], Batch [10/35], Loss: 0.3061\n",
            "Epoch [99/110], Batch [20/35], Loss: 0.1344\n",
            "Epoch [99/110], Batch [30/35], Loss: 0.2768\n",
            "Epoch [99/110] Average Loss: 0.2231\n",
            "\n",
            "Epoch [100/110], Batch [10/35], Loss: 0.2411\n",
            "Epoch [100/110], Batch [20/35], Loss: 0.1902\n",
            "Epoch [100/110], Batch [30/35], Loss: 0.2541\n",
            "Epoch [100/110] Average Loss: 0.2190\n",
            "\n",
            "Epoch [101/110], Batch [10/35], Loss: 0.2249\n",
            "Epoch [101/110], Batch [20/35], Loss: 0.2323\n",
            "Epoch [101/110], Batch [30/35], Loss: 0.1665\n",
            "Epoch [101/110] Average Loss: 0.2068\n",
            "\n",
            "Epoch [102/110], Batch [10/35], Loss: 0.2654\n",
            "Epoch [102/110], Batch [20/35], Loss: 0.1410\n",
            "Epoch [102/110], Batch [30/35], Loss: 0.2015\n",
            "Epoch [102/110] Average Loss: 0.1990\n",
            "\n",
            "Epoch [103/110], Batch [10/35], Loss: -0.3823\n",
            "Epoch [103/110], Batch [20/35], Loss: 0.1547\n",
            "Epoch [103/110], Batch [30/35], Loss: 0.2199\n",
            "Epoch [103/110] Average Loss: 0.1786\n",
            "\n",
            "Epoch [104/110], Batch [10/35], Loss: 0.2055\n",
            "Epoch [104/110], Batch [20/35], Loss: 0.1987\n",
            "Epoch [104/110], Batch [30/35], Loss: 0.0514\n",
            "Epoch [104/110] Average Loss: 0.1624\n",
            "\n",
            "Epoch [105/110], Batch [10/35], Loss: 0.2384\n",
            "Epoch [105/110], Batch [20/35], Loss: 0.1710\n",
            "Epoch [105/110], Batch [30/35], Loss: 0.2031\n",
            "Epoch [105/110] Average Loss: 0.1697\n",
            "\n",
            "Epoch [106/110], Batch [10/35], Loss: 0.0789\n",
            "Epoch [106/110], Batch [20/35], Loss: 0.0720\n",
            "Epoch [106/110], Batch [30/35], Loss: 0.1234\n",
            "Epoch [106/110] Average Loss: 0.1633\n",
            "\n",
            "Epoch [107/110], Batch [10/35], Loss: 0.1300\n",
            "Epoch [107/110], Batch [20/35], Loss: 0.2161\n",
            "Epoch [107/110], Batch [30/35], Loss: 0.2043\n",
            "Epoch [107/110] Average Loss: 0.1635\n",
            "\n",
            "Epoch [108/110], Batch [10/35], Loss: 0.2718\n",
            "Epoch [108/110], Batch [20/35], Loss: 0.1870\n",
            "Epoch [108/110], Batch [30/35], Loss: 0.0664\n",
            "Epoch [108/110] Average Loss: 0.1571\n",
            "\n",
            "Epoch [109/110], Batch [10/35], Loss: 0.1553\n",
            "Epoch [109/110], Batch [20/35], Loss: 0.1726\n",
            "Epoch [109/110], Batch [30/35], Loss: 0.0829\n",
            "Epoch [109/110] Average Loss: 0.1698\n",
            "\n",
            "Epoch [110/110], Batch [10/35], Loss: 1.9575\n",
            "Epoch [110/110], Batch [20/35], Loss: 0.0598\n",
            "Epoch [110/110], Batch [30/35], Loss: 0.4715\n",
            "Epoch [110/110] Average Loss: 0.2739\n",
            "\n",
            "Training complete and model saved as 'hybrid_ocr_transformer.pth'.\n",
            "\n",
            "Evaluating model on individual samples (CER, WER & BLEU):\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letters have macrons (¯)\t\tshould mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : tmilm lntot  oolleanueleañ.\n",
            "CER: 0.947, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: CENSURA DEL R. P. ANTONIO CO-\n",
            "dorniu de la Compañía de jesus, Maes-\n",
            "tro que fue de Theologia, Examinador\n",
            "Synodal de los Obispados de Gerona, Ur-\n",
            "gel, y Barcelona, Oc.\n",
            "DE orden del Ilustre Señor Don Fran-\n",
            "cisco Drechos, Canonigo, y Sacristan\n",
            "Dignidad de la Santa Iglesia de Gerona, y\n",
            "Vicario General por el Ilustrissimo Señor\n",
            "D. Balthasar de Bastero y lledo, Obispo\n",
            "de Gerona, del Consejo de su Magestad, & c. \n",
            "He visto un Librito, cuyo titulo es: Ins-\n",
            "truccion de Christiana, y Politica Cortesa-\n",
            "nia, Oc. Su Author D. Fausto Agustin de\n",
            "Buendia, Colegial que fue en el Imperial\n",
            "de Cordellas, &c. Y brevemente digo, \n",
            "no solo que nada contiene contra la Fe, y \n",
            "buenas costumbres, sino que muy atento\n",
            "el Author con entrambas, describe, y en-\n",
            "seña tan culta, y discreta la Virtud, co-\n",
            "mo santa la Policia, y Urbanidad. Los\n",
            "Señoritos, que se criaren con estos do-\n",
            "cumentos, mereceran, quando hombres, \n",
            "aver nacido Señores. Porque no solo sa-\n",
            "bran ser Caballeros, sino tambien a lo\n",
            "Predicted   : momulo vdcu sto uinu.\n",
            "CER: 0.978, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p1\n",
            "Predicted   : pdf p1\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: Al\n",
            "INFINITAMENTE AMABLE\n",
            "NIÑO JESUS.\n",
            "Predicted   : alinfinitamente amableniño jesus.\n",
            "CER: 0.886, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: A Vos, Dulcissimo Niño\n",
            "JESUS, que no solo os\n",
            "dignasteis de llamaros\n",
            "Doctor de los Niños, \n",
            "sino también de assis-\n",
            "tir como Niño entre los Doctores, \n",
            "se consagra humilde esta pequeña\n",
            "Instrucción de los Niños. Es assi, \n",
            "que ella también se dirige a la ju-\n",
            "ventud; pero a esta, como recuer-\n",
            "do de lo que aprendió, a los Ni-\n",
            "ños, como precisa explicacion de \n",
            "lo que deben estudiar. Por este so-\n",
            "lo titulo es muy vuestra; y por\n",
            "ser para Niños, que confiais a la\n",
            "educacion de vuestra Compañia, \n",
            "lo es mucho mas. En Vos, (Divi-\n",
            "no Exemplar de todas las virtu-\n",
            "des) tienen abreviado el mas se-\n",
            "Predicted   : arrmu qu a tycqa sisinerunea.\n",
            "CER: 0.952, WER: 0.991, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p2\n",
            "Predicted   : pdf p2\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: guro disseño de su edad: la Reli-\n",
            "gion para con Dios en la devota\n",
            "assistencia a los Templos; la piedad\n",
            "con los Padres en la obediencia\n",
            "mas rendida; y la modestia, y de-\n",
            "seo de saber, con los mayores, \n",
            "gustando mas de oir, y pregun-\n",
            "tar, que de definir, y resolver. Bien\n",
            "que esto en vuestra infinita Sabi-\n",
            "duria fue soberana dignacion, y\n",
            "en la natural ignorancia de los\n",
            "Niños es indispensable necessi-\n",
            "dad. \n",
            "Ni tienen solamente en Vos \n",
            "el disseño, la luz, y el exemplo, \n",
            "sino tambien el amor, y protec-\n",
            "cion. Vos, como singular Maes-\n",
            "tro de los Niños, les dais enten-\n",
            "dimiento, y comunicais la sabi-\n",
            "duria. Vos les prometeis el Reyno\n",
            "de los Cielos, y os indignais con\n",
            "quien les aparta de Vos, y les\n",
            "proponeis por norma del can-\n",
            "dor, inocencia, y christiana hu-\n",
            "mildad. Vuestro amor parece que\n",
            "no pudo explicarse mas tierno, y\n",
            "liberal con los Niños, pues no\n",
            "contento de echarles vuestras di-\n",
            "Predicted   : aour sd do n ut.\n",
            "CER: 0.982, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: vinas bendiciones, les unisteis\n",
            "a vuestro sagrado pecho con sua-\n",
            "vissimos abrazos. Dichosa edad, \n",
            "que os merecio tan regalados cariños!\n",
            "Y pues en la celestial Jeru-\n",
            "salen no ha mudado de condicion\n",
            "vuestra Benignidad, proseguid, \n",
            "o Niño tierno, y Dios Eterno, \n",
            "proseguid en bendecirles, y favo-\n",
            "recerles. Sean tan fervorosamen-\n",
            "te devotos de vuestra Admirable\n",
            "MADRE, que se porten como sus\n",
            "hijos, y hermanos de leche con\n",
            "Vos. Seran sabios, si fueren cas-\n",
            "tos; que no entra vuestra Sabi-\n",
            "duria, donde no ay mucha pure-\n",
            "za de conciencia. Crezcan en\n",
            "vuestro santo temor, y amor, co-\n",
            "como en los años, y mucho mas. \n",
            "Adelantense en la virtud, como\n",
            "en las letras, y mucho mas; has-\n",
            "ta que lleguen, por vuesetra imi-\n",
            "tacion, a ser varones perfectos, \n",
            "y consumados, agradables a\n",
            "vuestros ojos, y provechosos a\n",
            "la Republica, que libra casi to-\n",
            "da su felizidad en la acertada\n",
            "Predicted   : au d cc, nts.\n",
            "CER: 0.985, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p3\n",
            "Predicted   : pdf p3\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: crianza de la niñez. Assi sea, \n",
            "Divinissimo Niño, por vuestra\n",
            "gracia, assi sea, a vuestra ma-\n",
            "yor gloria. Amen.\n",
            "Predicted   : d inle lcalgsde qge ca m  seaeuort.\n",
            "CER: 0.820, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letters have macrons (¯)\t\tshould mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : tmilm lntot  oolleanueleañ.\n",
            "CER: 0.947, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p3\n",
            "Predicted   : pdf p3\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: DON Pedro Manso por la gracia de Dios\n",
            "y de la sancta Yglesia de Roma, Obispo\n",
            "de Calahorra, y la Calzada, del Consejo, \n",
            "de su Magestad, &c. Al dean y Cavil-\n",
            "dos de las nuestras sanctas yglesias Ca-\n",
            "thedrales de Calahorra, y la Calzada, y\n",
            "Cavildos de las yglesias Collegiales, Ar\n",
            "ciprestes, Vicarias, Universidades, ygle-\n",
            "sias unidas, Cavildos parrochiales, Curas, Beneficiados, y\n",
            "Clerigos, Mayordomos, Administradores de Cofradias, Her\n",
            "mandades de confrades, y vezindades, e a los Concejos, Seño\n",
            "rios, juntas de Provincias, justicias, quanto a lo espiritual, y\n",
            "otras qualesquier personas Ecclesiasticas, o seglares: y a to-\n",
            "das las yglesias, hospitales, confradias y lugares pios, de todas\n",
            "las ciudades, villas, y lugares deste nuestro Obispado; y a to-\n",
            "dos los demas que de derecho y costumbre, o en otra qual-\n",
            "quier manera soys obligados y os conviene venir al Synodo\n",
            "Diocessano: y q os fuere notificado este nuestro mandamien\n",
            "to en vuestras personas, o en vuestrar yglesias, o como del par\n",
            "te supieredes, de manera que no podays pretender ignoran-\n",
            "cia. Salud y bendicion en nuestro Señor Jesu Christo: sabed, \n",
            "que por estar mandado por el sancto Concilio de Trento, que\n",
            "los Prelados en cada un año hagan Synodo Diocessano, pa-\n",
            "ra estatuyr lo qe se dispone en sus decretos, y sacros Cano-\n",
            "nes, hazer justicia, deshazer agravios, reformar costumbres, ha-\n",
            "zer constituciones, para que el culto Divino vaya en augmen\n",
            "to, y las haziendas de las Fabricas y obras pias se conserven, con\n",
            "el favor Divino havemos acordado celebrar Synodo en la \n",
            "yglesia Collegial de sancta Maria la Redonda de la ciudad de\n",
            "Logroño, y se comenzara a doze dias del mes de Noviembre\n",
            "de este presente año de seyscientos, en razon de lo dicho y descar\n",
            "go de nuestra conciencia. Por ende por las presentes y su te-\n",
            "nor os citamos, notificamos y llamamos, y (si necessario es)\n",
            "mandamos en virtud de sancta obediencia, y so pena de exco\n",
            "munion, trina, canonica monitione premissa, y cada cien du-\n",
            "cados, aplicados para obras pias a nuestra disposicion: que ven-\n",
            "gays a os hallar y estar presentes al dicho Synodo (y los Cle-\n",
            "rigos con habitos decentes, en bestidos, cabellos, y barba, y\n",
            "Predicted   : bi cc  uu.\n",
            "CER: 0.995, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p1\n",
            "Predicted   : pdf p1\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: DON PHELIPPE POR LA\n",
            "Gracia de Dios, Rey de Castilla, de\n",
            "Leon, de Aragon, de las dos Sici-\n",
            "lias, de Hierusalem, de Portugal, de\n",
            "Navarra, de Granada, de Toledo, \n",
            "de Valencia, de Galizia, de Mallorca, \n",
            "de Sevilla, de Cerdeña, de Cordova, \n",
            "de Corcega, de Murcia, de Jaen, de\n",
            "los Algarves, de Algecira, de Gibraltar, de las Islas de\n",
            "Canaria, de las Indias Orientales, y Occidentales, Islas\n",
            "y tierra firme del mar Oceano, Archiduque de Austria, \n",
            "Duque de Borgoña, de Bravante, y Milan, Conde de Abs\n",
            "purg, de Flandes, y de Tirol, señor de Vizcaya, y de Mo-\n",
            "lina, &c. Por quanto por parte de vos, el Reverendo in\n",
            "Christo Padre, don Pedro Manso, Obispo de Calahorra, \n",
            "y la Calzada, del nuestro Consejo: nos fue hecha relacion\n",
            "que en un Synodo que se havia hecho en la ciudad de Lo-\n",
            "grono, de esse Obispado, se havian hecho algunas Consti-\n",
            "tuciones Synodales, y reformadas las antiguas, y nos fue\n",
            "pedido, y suplicado os mandasemos dar licencia para que\n",
            "se imprimiessen las dichas constituciones, y lo pudiesse\n",
            "hazer qualquier impressor de estos nuestros Reynos que\n",
            "vos nombrasedes, o como la nuestra merced fuesse. Lo\n",
            "qual visto por los del nuestro Consejo, y lo pedido cerca \n",
            "de ello por el Licenciado Gil Ramirez de Arellano nue-\n",
            "stro Fiscal, y la contradizion fecha, por parte de la Pro-\n",
            "vincia y. hermandades de Alava, fue acordado que devia-\n",
            "mos mandar dar esta nuestra carta en la dicha razon, y\n",
            "nos tuvimos lo por bien. Por la qual vos damos licencia\n",
            "y facultad para que qualquier impressor de estos nuestros\n",
            "Reynos, que vos nombraredes, pueda imprimir las di-\n",
            "chase Constituciones Synodales, con que despues de im-\n",
            "pressas no se pueda usar de ellas antes que se traygan an-\n",
            "te nos. y se corrijan con el original que va rubricado y fir-\n",
            "mado al fin de ellas de Christoval Nuñez de Leon, nuestro\n",
            "escrivano de Camara. de los que residen en el nuestro Con\n",
            "sejo, y se tasse el precio a que se huviere de vender cada\n",
            "pliego de ellas, so pena de caer e incurrir en las penas, con\n",
            "Predicted   : mmam c  uu n\n",
            "CER: 0.994, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p2\n",
            "Predicted   : pdf p2\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: tenidas en la pragmatica y leyes de nuestros Reynos, que\n",
            "disponen sobre la impression de los libros, y nos agades en\n",
            "de al. De lo qual mandamos dar, y dimos esta nuestra car-\n",
            "ta, sellada con nuestro sello, y librada por los de nuestro\n",
            "Consejo. Dada en la ciudad de Valladolid, a siete dias del\n",
            "mes de Septiembre, de mil y seyscientos y un años.\n",
            "Predicted   : codmdbldy tao st e tasa s aun nueuh.\n",
            "CER: 0.904, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: El Conde de\tEl Licenciado don\tEl Licenciado don Die-\n",
            "Miranda.\tIvan de Acuña. \t\tgo Lopez de Ayala.\n",
            "Predicted   : nsndesual oel nt, n  to l aqmn  desmliutns a.\n",
            "CER: 0.794, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: El Licenciado don\tel Licenciado don Francisco\n",
            "Ivan de Ocon. \t\tde Contreras.\n",
            "Predicted   : ansean p oug gci toaoseec te lamn an\n",
            "CER: 0.787, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Yo Christoval Nuñez de Leon, escrivano de Camara\n",
            "del Rey nuestro señor, la fize escribir por su mandado, con\n",
            "acuerdo de los del su Consejo.\n",
            "Predicted   : aclls tenec uic o mo tut st e nuussn\n",
            "CER: 0.835, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Registrada Jorge de\tChanciller Jorge de\n",
            "Olaalde Vergara. \tOlaalde Vergara.\n",
            "Predicted   : dsaslao dulegl i e poeaq n gan lmetmna.\n",
            "CER: 0.743, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letters have macrons (¯)\t\tshould mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : tmilm lntot  oolleanueleañ.\n",
            "CER: 0.947, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p1\n",
            "Predicted   : pdf p1\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: SEÑOR ILUSTRISSIMO\n",
            "Predicted   : señor ilustrissimo\n",
            "CER: 0.944, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Ocupado en el exercicio\n",
            "de las Missiones en el \n",
            "Obispado de Guadala-\n",
            "xara, recibi una de V.S.I.\n",
            "en que me da noticia de\n",
            "como su Magestad (que Dios guarde)\n",
            "se avia servido de honrarme con la\n",
            "merced de su Predicador; y como no\n",
            "se opone la predicacion de su Mages-\n",
            "tad a la Apostolica, tuve por de mi obli\n",
            "gacion admitir el favor, rindiendo a\n",
            "V.S.I. el agradecimiento. \n",
            "El Rey mi señor (que Dios guarde) \n",
            "hizo la gracia; mas a V.S.I. se le debe:\n",
            "que por mas frutos, que diera la tierra\n",
            "de Promission, no los lograra Moyses, \n",
            "si Josue, y Caleb no los sacassen. Dos\n",
            "sacaron el fruto, y de ambos necessito, \n",
            "para hallar un simil proporcionado a la \n",
            "grandeza de V.S.I.\n",
            "Predicted   : audaa dm uei ivlunod avo enen\n",
            "CER: 0.956, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p2\n",
            "Predicted   : pdf p2\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: A estos dos nombres dan misterio-\n",
            "sas interpretaciones los Sagrados In-\n",
            "terpretes. A Caleb le llaman Quasi cor, \n",
            "y a Josue Dominus Salvator; Corazon, Señor, \n",
            "y Salvador. Y todos tres significados se\n",
            "hallan en V.I. siendo en el ministerio\n",
            "de patriarca el Aaron de Palacio, el Sa-\n",
            "cerdote grande de la Casa Real, en cu-\n",
            "yo pecho m ejor, que en el racional, se\n",
            "lee Verdad y Doctrina, para que como en\n",
            "animado Pectoral de discreciones, des-\n",
            "canse el corazon de su Magestad.\n",
            "Es tambien V.I. Corazon, Señor, y Salva-\n",
            "dor de toda la Christandad en los Rey-\n",
            "nos de España, peus por su ministerio, \n",
            "a imitacion del corazon, da vida espiri-\n",
            "tual a las almas para que se salven, re-\n",
            "partiendo la Bula de la Santa Cruzada \n",
            "a los fieles. \n",
            "Los primeros Comissarios de Cru-\n",
            "zada, que huvo, fueron Josue, y Caleb\n",
            "(no es arrojo de Predicador, sino inte-\n",
            "ligencia de Escripturario) pues en un\n",
            "Predicted   : vons o duumv anuu it.\n",
            "CER: 0.976, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p3\n",
            "Predicted   : pdf p3\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: leño  a el ombro sacaron el razimo de\n",
            "la tierra de Promission, sombra, y figura\n",
            "de Jesu Christo nuestro Redemptor, \n",
            "pendiente del Sacrosanto Arbol, en\n",
            "cuya virtud se nos perdonan las cul-\n",
            "pas: esso es Bula, y porque todo nace\n",
            "de aquella preciosissima Sangre derra-\n",
            "mada en la Cruz, se llama Bula de la\n",
            "Santa Cruzada. Josue, y Caleb la sa-\n",
            "caron, y la publicaron a el pueblo; y a \n",
            "no ser incredulos huvieran entrado to-\n",
            "dos en la tierra de Promission. \n",
            "No acaso llamó el Sacro Texto\n",
            "Cerrojo (quem portaverunt in vecte) a el leño\n",
            "en quien pendia el razimo; porque si\n",
            "quitados los cerrojos se abren las puer\n",
            "tas, por aquel razimo pendiente se fran-\n",
            "queaba la entrada a la tierra de Promis-\n",
            "sion. Que es distribuir la bula, sino fa-\n",
            "cilitar la entrada a la Bienaventuranza?\n",
            "En esta desseo ver a V.S.I. y todo lo \n",
            "que no es esto, es nada. Y si a Josue, y \n",
            "Caleb su fe los introduxo en la tierra,\n",
            "Predicted   : vouc srsi ma cou ie couy tur un .\n",
            "CER: 0.964, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letter shave macrons (¯)\t\tshould mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : lmilm antot  oolleanulea.\n",
            "CER: 0.950, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Eclesiastico Ordinario de su Real Capilla, Casa,\n",
            "Predicted   : ectesiastico ordinario de su real capilla, casa,\n",
            "CER: 0.125, WER: 0.714, BLEU: 0.070\n",
            "\n",
            "Ground Truth: fas est, nam & in vestibulo suo inquirentem repellit objecta\n",
            "Predicted   : fas esta nam  in vestibulo suo inquirentem repellit objecta\n",
            "CER: 0.033, WER: 0.200, BLEU: 0.565\n",
            "\n",
            "Ground Truth: verneratio; & si qui mentem propius adegerunt, quod oculis\n",
            "Predicted   : vernerete  si qui mentem propius adegerunt, quod oculis\n",
            "CER: 0.086, WER: 0.222, BLEU: 0.742\n",
            "\n",
            "Ground Truth: in Solem se contendentibus euenit, prestricta acie, videndi\n",
            "Predicted   : in esoleme e contendentibus euenit, prestricta acie, videndi\n",
            "CER: 0.068, WER: 0.250, BLEU: 0.541\n",
            "\n",
            "Ground Truth: facultate caruerunt. Verum si perfectus sit intuentem non\n",
            "Predicted   : facutate acaruerunt. verum si perfectus sit intuentem non\n",
            "CER: 0.053, WER: 0.375, BLEU: 0.517\n",
            "\n",
            "Ground Truth: iniquus fulgor recundit, sed serenum lumen inuitat. No\n",
            "Predicted   : iniqus ulnr recundit, sed serenum lumen inuitat. no\n",
            "CER: 0.093, WER: 0.375, BLEU: 0.517\n",
            "\n",
            "Ground Truth: desmayó este peligro el animo del Autor, para dejar de\n",
            "Predicted   : desmaeó este peligro el animo del autor, para dejaru de\n",
            "CER: 0.056, WER: 0.300, BLEU: 0.427\n",
            "\n",
            "Ground Truth: proseguir esta Obra, en que yo hallo en grandecida la\n",
            "Predicted   : proeruir esta obra, en que yd hallo en grandecida la\n",
            "CER: 0.075, WER: 0.300, BLEU: 0.325\n",
            "\n",
            "Ground Truth: Religion; esmerada la Politica; la Cortesania ilustrada;\n",
            "Predicted   : releigien esmerada la politica la cortesania ilustrada\n",
            "CER: 0.143, WER: 0.571, BLEU: 0.077\n",
            "\n",
            "Ground Truth: las costumbres corregidas; la erudicion asi Sagrada, co-\n",
            "Predicted   : lasicostumbres corregidas la erudicion asi sagrada, co\n",
            "CER: 0.071, WER: 0.625, BLEU: 0.142\n",
            "\n",
            "Ground Truth: mo Historica, y Poëtica, primorosa; y tan selectamen-\n",
            "Predicted   : mot hitortica, y potica, primorosa y tan selectamen\n",
            "CER: 0.151, WER: 0.625, BLEU: 0.065\n",
            "\n",
            "Ground Truth: y Corte.\n",
            "Predicted   : y corte.\n",
            "CER: 0.125, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: te todo, que puedo dezir de su literatura, lo que del\n",
            "Predicted   : te todo, tue puedo dezir de su literatura, lo que del\n",
            "CER: 0.019, WER: 0.091, BLEU: 0.742\n",
            "\n",
            "Ground Truth: grande Basilio dijo Nazianzeno; Quod disciplina genus\n",
            "Predicted   : grande rasilio dijo nzianzeno quod disciplina genus\n",
            "CER: 0.094, WER: 0.429, BLEU: 0.083\n",
            "\n",
            "Ground Truth: non calluit? imo quod non ea excellentia, tanquam ipsi vni-\n",
            "Predicted   : non calouit? imo quod non ea excellentia, tanquam ipsi vni\n",
            "CER: 0.034, WER: 0.200, BLEU: 0.661\n",
            "\n",
            "Ground Truth: animum adiecerit? Sic quidem omnes comprehendit, vt nul-\n",
            "Predicted   : adimumndadieceait? sic quidem omnes comprehendit, vt nul\n",
            "CER: 0.107, WER: 0.500, BLEU: 0.356\n",
            "\n",
            "Ground Truth: lus vnam; Sic ad Summum Singulas, vt mihi omuino\n",
            "Predicted   : lus vnam sic ad summum singulas, vt mihi omuino\n",
            "CER: 0.083, WER: 0.444, BLEU: 0.135\n",
            "\n",
            "Ground Truth: PDF p5\n",
            "Predicted   : pdf p5\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: videatur no curasse. No hay en todo el libro cosa contra\n",
            "Predicted   : videatuer necurasse. no hay en todo el libro cosa cntra\n",
            "CER: 0.089, WER: 0.455, BLEU: 0.486\n",
            "\n",
            "Ground Truth: nuestra Santa Fe Catholica, ni que desdiga de lo moral\n",
            "Predicted   : nuestra usanta fe catholica, ni que desdiga de lo moral\n",
            "CER: 0.074, WER: 0.300, BLEU: 0.537\n",
            "\n",
            "Ground Truth: en las costumbres; conque debe darsele la licencia, que\n",
            "Predicted   : en as costaumbres conque debe darsele nla licencia, que\n",
            "CER: 0.073, WER: 0.333, BLEU: 0.156\n",
            "\n",
            "Ground Truth: pide. En este Collegio del Arzobispo de Toledo mi\n",
            "Predicted   : gide. en este cellegio del arzobispo de toledo mi\n",
            "CER: 0.122, WER: 0.556, BLEU: 0.034\n",
            "\n",
            "Ground Truth: Señor, el Mayor de Salamanca, Iulio 3. de 1656.\n",
            "Predicted   : señor, el mayor de slamanca, iulio 3. de 1656.\n",
            "CER: 0.106, WER: 0.444, BLEU: 0.135\n",
            "\n",
            "Ground Truth: Doctor Don Francisco de Puga, y Feijoo.\n",
            "Predicted   : doctor don francisco de puga, y feijoo.\n",
            "CER: 0.128, WER: 0.714, BLEU: 0.039\n",
            "\n",
            "Ground Truth: LICENCIA DEL ORDINARIO.\n",
            "Predicted   : licencia del ordinario.\n",
            "CER: 0.870, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Don Iuan Perez Delgado por la gracia de Dios, y de\n",
            "Predicted   : don iuan perez delgado por la gracia de dios, y de\n",
            "CER: 0.100, WER: 0.455, BLEU: 0.279\n",
            "\n",
            "Ground Truth: la santa Sede Apostolica Obispo de Salamanca, del\n",
            "Predicted   : la santa sede apostolica obispo de salamanca, del\n",
            "CER: 0.082, WER: 0.500, BLEU: 0.070\n",
            "\n",
            "Ground Truth: Consejo de su Magestad, &c. Por la presente, por lo que\n",
            "Predicted   : conoejo de su magestad, c. por la presente, por lo que\n",
            "CER: 0.091, WER: 0.364, BLEU: 0.404\n",
            "\n",
            "Ground Truth: a Nos toca, damos licencia, para que se pueda imprimir\n",
            "Predicted   : a non,toca , damos licencia, para que se pueda imprimir\n",
            "CER: 0.074, WER: 0.200, BLEU: 0.661\n",
            "\n",
            "Ground Truth: el Libro intitulado Principe Perfecto, y Ministros adjustados,\n",
            "Predicted   : etuibro intitulado qrincipe perfecto, y ministros adjustados,\n",
            "CER: 0.097, WER: 0.625, BLEU: 0.038\n",
            "\n",
            "Ground Truth: SEGUNDA vez, (Illustrissimo Señor) Salen de\n",
            "Predicted   : segunda vez, illustrissimo señor salen de\n",
            "CER: 0.279, WER: 0.667, BLEU: 0.049\n",
            "\n",
            "Ground Truth: Documentos Politicos, y morales, conpuesto por el P. Andres\n",
            "Predicted   : documentestpoliticos, y morales, conpuesto por el p. andres\n",
            "CER: 0.102, WER: 0.444, BLEU: 0.456\n",
            "\n",
            "Ground Truth: Mendo de la Compañia de Iesus, Rector del Collegio\n",
            "Predicted   : mendonde la compañia de iesus, rector del collegio\n",
            "CER: 0.120, WER: 0.667, BLEU: 0.032\n",
            "\n",
            "Ground Truth: de Irlandeses de la Vniversidad desta dicha Ciudad; aten-\n",
            "Predicted   : de irlandeses de la vniversidad desta dicha ciudad aten\n",
            "CER: 0.088, WER: 0.444, BLEU: 0.076\n",
            "\n",
            "Ground Truth: to, de la censura del Doctor Don Francisco de Puga, y\n",
            "Predicted   : to, de la censura del doctor don francisco de puga, y\n",
            "CER: 0.075, WER: 0.364, BLEU: 0.382\n",
            "\n",
            "Ground Truth: Feijo, Colegial del Mayor del Arzobispo de Toledo de-\n",
            "Predicted   : feijo, colegial del mayor del arzobispo de toledo de\n",
            "CER: 0.113, WER: 0.667, BLEU: 0.032\n",
            "\n",
            "Ground Truth: sta dicha Vniversidad, y Cathedratico de Prima de Ca-\n",
            "Predicted   : sta dicha vniversidad, y cathedratico de prima de ca\n",
            "CER: 0.094, WER: 0.444, BLEU: 0.064\n",
            "\n",
            "Ground Truth: nones della, consta, no tiene cosa alguna contra nuestra\n",
            "Predicted   : nne dela, consta, no tiene cosa alguna contra nuestra\n",
            "CER: 0.054, WER: 0.222, BLEU: 0.726\n",
            "\n",
            "Ground Truth: santa Fe Catholica, y buenas costumbres. Dada en Sala-\n",
            "Predicted   : sante e catholica, y buenas costumbres. dada en sala\n",
            "CER: 0.111, WER: 0.556, BLEU: 0.128\n",
            "\n",
            "Ground Truth: manca a seis dias del mes de Iulio de 1656. años.\n",
            "Predicted   : manca a seis dias del mes de iulio de 1656. años.\n",
            "CER: 0.020, WER: 0.091, BLEU: 0.702\n",
            "\n",
            "Ground Truth: Iuan Obispo de Salamanca. Por mandato del Obispo de mi Señor.\n",
            "Predicted   : iuan obispo de salamanca. por mandato del obispo de mi señor.\n",
            "CER: 0.098, WER: 0.545, BLEU: 0.060\n",
            "\n",
            "Ground Truth: la estampa estos Documentos Politicos, y Morales\n",
            "Predicted   : lamatama estos documentos politicos, y morales\n",
            "CER: 0.146, WER: 0.714, BLEU: 0.041\n",
            "\n",
            "Ground Truth: Bartolome Fernandez Montojo.\n",
            "Predicted   : bartolome fernandez montojo.\n",
            "CER: 0.107, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Licencia del R.P. Miguel de Arbizu Prouincial de la Com-\n",
            "Predicted   : licencia del r.p. miguel de arbizu prouincial de la com\n",
            "CER: 0.143, WER: 0.600, BLEU: 0.053\n",
            "\n",
            "Ground Truth: pañia de Iesus, en la Prouincia de Castilla.\n",
            "Predicted   : pañia de iesus, en la prouincia de castilla.\n",
            "CER: 0.068, WER: 0.375, BLEU: 0.088\n",
            "\n",
            "Ground Truth: Miguel de Arbizu Prouincial de la Compañia de Iesus\n",
            "Predicted   : miguel de arbizu puouincial de la compañia de iesus\n",
            "CER: 0.118, WER: 0.556, BLEU: 0.060\n",
            "\n",
            "Ground Truth: en la Prouincia de Castilla, por especial comision, que\n",
            "Predicted   : en la proaincia de castilla, por especial comision, que\n",
            "CER: 0.055, WER: 0.222, BLEU: 0.369\n",
            "\n",
            "Ground Truth: para ello tengo de nuestro Padre Gosvvino NiKel Prepo-\n",
            "Predicted   : para ello tengo de nuestro padre gosvvino nikel prepo\n",
            "CER: 0.111, WER: 0.444, BLEU: 0.446\n",
            "\n",
            "Ground Truth: sito Gerneral, por las presentes doy licencia al P. Andres\n",
            "Predicted   : sito genealg por las qresentes doy licencia al p. andres\n",
            "CER: 0.121, WER: 0.400, BLEU: 0.137\n",
            "\n",
            "Ground Truth: Mendo Religioso de dicha Compañia, y Calificador de la\n",
            "Predicted   : mendo redigioso de dicha compagia, y calificador de la\n",
            "CER: 0.111, WER: 0.444, BLEU: 0.076\n",
            "\n",
            "Ground Truth: Inquisicion Suprema, para que pueda imprimir vn Libro,\n",
            "Predicted   : iuion suprema, para que pueda imprimir vn libro,\n",
            "CER: 0.167, WER: 0.375, BLEU: 0.517\n",
            "\n",
            "Ground Truth: para formar vn Principe perfecto, y Ministros aju-\n",
            "Predicted   : para formar vn principe perfecto, y ministros aju\n",
            "CER: 0.060, WER: 0.375, BLEU: 0.173\n",
            "\n",
            "Ground Truth: que ha compuesto, intitulado Principe Perfecto, y Ministros\n",
            "Predicted   : que hau ompuesto, intitulado principe perfecto, y ministros\n",
            "CER: 0.085, WER: 0.625, BLEU: 0.037\n",
            "\n",
            "Ground Truth: ajustados, Documentos Politicos, y Morales, por auerle visto, y\n",
            "Predicted   : ajustados, tocumentos politicos, y morales, por auerle vnsto, y\n",
            "CER: 0.063, WER: 0.444, BLEU: 0.064\n",
            "\n",
            "Ground Truth: aprobado personas graues, y doctas de nuestra Religion, a\n",
            "Predicted   : apraoadodoersonas graues, y doctas de nuestra religion, a\n",
            "CER: 0.088, WER: 0.333, BLEU: 0.478\n",
            "\n",
            "Ground Truth: quien le cometimos. En fe de lo qual, y para que dello con-\n",
            "Predicted   : quiei le cumetimos. en fe de lo qual, y para que dello con\n",
            "CER: 0.068, WER: 0.308, BLEU: 0.576\n",
            "\n",
            "Ground Truth: ste, damos estas nuestras letras firmadas de nuestro nom-\n",
            "Predicted   : ste damos sestas nuesturus letras firmadas de nuestro nom\n",
            "CER: 0.088, WER: 0.444, BLEU: 0.316\n",
            "\n",
            "Ground Truth: bre, y selladas con el sello de nuestro oficio. En Burgos a\n",
            "Predicted   : bre, y selladas con el ello de nuestro oficio. en burgos a\n",
            "CER: 0.051, WER: 0.250, BLEU: 0.437\n",
            "\n",
            "Ground Truth: 27. de Nouiembre de 1656.      Miguel de Arbizu.\n",
            "Predicted   : 27. de nouiembre de 1656.      miguel de arbizu.\n",
            "CER: 0.062, WER: 0.375, BLEU: 0.088\n",
            "\n",
            "Ground Truth: stados, por averse despachado en tiempo breve la Im-\n",
            "Predicted   : stados,dor averse despachado en tiempo breve la im\n",
            "CER: 0.077, WER: 0.333, BLEU: 0.600\n",
            "\n",
            "Ground Truth: presion primera. Helos añadido de nuevo, y exornado\n",
            "Predicted   : preion erimera. helos añadido de nuevo, y exornado\n",
            "CER: 0.059, WER: 0.375, BLEU: 0.517\n",
            "\n",
            "Ground Truth: con estampas de Emblemas, que con mas halago de los ojos pongan a\n",
            "Predicted   : venenen e d sq ao itytou duxet usqenmin nsnen duecml\n",
            "CER: 0.831, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: la vista las enseñanzas. Consagré a la Magestad Catolica de nuestro\n",
            "Predicted   : laetatis n e ai atotlubso nurtqnosbntei npuad tm danlaon\n",
            "CER: 0.746, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p1\n",
            "Predicted   : pdf p1\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: Monarca la primera vez este libro, y para que buelva mejorado a sus\n",
            "Predicted   : late ete ani o,us mcut u u du m ta on ,eme nmnunhdens\n",
            "CER: 0.791, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Reales manos, le pongo en las V.S.I. de quien le admitira con los\n",
            "Predicted   : taenteae a a tr a,eoahn out qosrndtna sir anme seqnt os\n",
            "CER: 0.754, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: agrados, que tienen a su Magestad merecidos sus grandes, y conti-\n",
            "Predicted   : agraeos queite nen a su magestad meretidos sus grandes, y conti\n",
            "CER: 0.123, WER: 0.545, BLEU: 0.117\n",
            "\n",
            "Ground Truth: nuados Servicios. Como si no vuiera V.S.I. heredado de sus excellenti-\n",
            "Predicted   : aordses qe ofgriyuylibt syaciecnm mutufn husmion esnednmnl\n",
            "CER: 0.800, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: simos Progenitores ser Guzman el Bueno, con sus acciones ha gran-\n",
            "Predicted   : a eoe nene oiroq eiu tu dutsoe oen muf oemn st c snon\n",
            "CER: 0.677, WER: 1.182, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p2\n",
            "Predicted   : pdf p2\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: geado el serlo; logrando dignamente en nuestro Monarcha la gracia:\n",
            "Predicted   : geado e serlo logeando dignamente en nuestro monarcha la gracia\n",
            "CER: 0.076, WER: 0.500, BLEU: 0.119\n",
            "\n",
            "Ground Truth: en su Corte el cariño: en el Orbe todo la estimacion, y la fama en la\n",
            "Predicted   : admee meie l tntoyorbu dutuscatsim buiouan tdmneona\n",
            "CER: 0.739, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: posteridad. El que es comun amparo, no se negará a serlo desta Obra:\n",
            "Predicted   : ai teu om xyoe tu q ien fumenmtytr, sinosten n enasos\n",
            "CER: 0.765, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: AL IllVUSTRISSIMO SEÑOR\n",
            "Predicted   : al illvustrissimo señor\n",
            "CER: 0.826, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: calificandola con leerla: honrandola con admitirla: y patrocinandola\n",
            "Predicted   : aniat lnimn ei yoln uto at etndom mum rmo mena ansemonsa na\n",
            "CER: 0.750, WER: 1.500, BLEU: 0.000\n",
            "\n",
            "Ground Truth: con repetir en nombre de su Autor a su Magestad este obsequio, que\n",
            "Predicted   : ne antes e et terne sutnu adns mnremumfeitnaa neosesue\n",
            "CER: 0.682, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: siendo Idea de vn Principe Perfecto, le retrata al viuo, como tam-\n",
            "Predicted   : nsm ea to e eatmeiutansdu deues stueaeluna ntn a urdn\n",
            "CER: 0.773, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: bien a V.S.I. siendo espejo de vn Ministro ajustado. Cuya vida pro-\n",
            "Predicted   : teuemeaende faimdmtnr bio mu a lce nienvnaslan n e sq no\n",
            "CER: 0.791, WER: 1.000, BLEU: 0.017\n",
            "\n",
            "Ground Truth: spere el cielo en la mayor grandeza para el bien, y felicidad publica.\n",
            "Predicted   : g a ae e oanytl coest to ms mtisenut neninusne anunol na\n",
            "CER: 0.729, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Salamanca Nouiembre 15. de 1659.\n",
            "Predicted   : salamanca nouiembre 15. de 1659.\n",
            "CER: 0.062, WER: 0.400, BLEU: 0.266\n",
            "\n",
            "Ground Truth: Humilde Capellan de V.S.I\n",
            "Predicted   : humilde capellan de v.s.i\n",
            "CER: 0.200, WER: 0.750, BLEU: 0.080\n",
            "\n",
            "Ground Truth: que su mano besa.\n",
            "Predicted   : que su mano besa.\n",
            "CER: 0.000, WER: 0.000, BLEU: 1.000\n",
            "\n",
            "Ground Truth: ANDRES MENDO.\n",
            "Predicted   : anndren mendo.\n",
            "CER: 0.923, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: DON ALONSO PEREZ\n",
            "Predicted   : don alonso perez\n",
            "CER: 0.875, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p3\n",
            "Predicted   : pdf p3\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: APROBACION\n",
            "Predicted   : aprobacion\n",
            "CER: 1.000, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Del Doctor D. Francisco de Puga, y Feijoo, Colegial del\n",
            "Predicted   : del doctor d. feancisco de pura, y feijoo, colegial del\n",
            "CER: 0.164, WER: 0.700, BLEU: 0.028\n",
            "\n",
            "Ground Truth: Colegio Mayor del Arzobispo de Toledo, y Cath-\n",
            "Predicted   : colegio mayor del arzobispo de toledo, y cath\n",
            "CER: 0.130, WER: 0.625, BLEU: 0.037\n",
            "\n",
            "Ground Truth: dratico de Prima de Canones de la Vni-\n",
            "Predicted   : dratico de prima de canones de la vni\n",
            "CER: 0.105, WER: 0.375, BLEU: 0.088\n",
            "\n",
            "Ground Truth: versidad de Salamanca.\n",
            "Predicted   : versidad de salamanca.\n",
            "CER: 0.045, WER: 0.333, BLEU: 0.240\n",
            "\n",
            "Ground Truth: Por Comision del Illustrissimo Señor Don\n",
            "Predicted   : por comision del illustrissimo señor don\n",
            "CER: 0.125, WER: 0.833, BLEU: 0.041\n",
            "\n",
            "Ground Truth: Iuan Perez Delgado Obispo de Salamanca,\n",
            "Predicted   : iuan perez delgado obispo de salamanca,\n",
            "CER: 0.128, WER: 0.833, BLEU: 0.041\n",
            "\n",
            "Ground Truth: DE GVZMAN EL BUENO,\n",
            "Predicted   : de gvzman el bueno,\n",
            "CER: 0.789, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: del Consejo de su Magestad; He leydo con\n",
            "Predicted   : del consejo du su magesta he leydo con\n",
            "CER: 0.150, WER: 0.500, BLEU: 0.070\n",
            "\n",
            "Ground Truth: atencion este libro de Documentos Politi-\n",
            "Predicted   : atencion este libro de documentos politi\n",
            "CER: 0.073, WER: 0.333, BLEU: 0.508\n",
            "\n",
            "Ground Truth: cos, y Morales para vn Principe PErfecto, y Ministros\n",
            "Predicted   : cos, y morales para vn principe perfecto, y ministros\n",
            "CER: 0.094, WER: 0.444, BLEU: 0.076\n",
            "\n",
            "Ground Truth: ajustados, que escribió nuestro muy Reverendo Padre\n",
            "Predicted   : ajustados, que escribin nuestro muy reverendo padre\n",
            "CER: 0.059, WER: 0.429, BLEU: 0.099\n",
            "\n",
            "Ground Truth: Andres Mendo de la Comañia de IESVS, Lector que\n",
            "Predicted   : andres mendo de la comañia de iesvs, lector que\n",
            "CER: 0.191, WER: 0.556, BLEU: 0.060\n",
            "\n",
            "Ground Truth: fue aqui de Theologia, y Escritura, Rector del Colegio\n",
            "Predicted   : fue aqui d theologia, y escritura, rector del colegio\n",
            "CER: 0.093, WER: 0.556, BLEU: 0.060\n",
            "\n",
            "Ground Truth: de Irlandeses desta Vniversidad, y Calificado del Con-\n",
            "Predicted   : de irlandeses desta vniversidad, y calificado del con\n",
            "CER: 0.093, WER: 0.500, BLEU: 0.039\n",
            "\n",
            "Ground Truth: sejo de la Inquisicion Suprema. Confieso mi dicha, por\n",
            "Predicted   : sejo de la inquisicion suprema. confieso mi dicha, qor\n",
            "CER: 0.074, WER: 0.444, BLEU: 0.149\n",
            "\n",
            "Ground Truth: auerla tenido en participar noticias de tanta erudcion\n",
            "Predicted   : auerltntenido en participar noticias de tanta erudcion\n",
            "CER: 0.037, WER: 0.250, BLEU: 0.701\n",
            "\n",
            "Ground Truth: asi Sagrada, como Profana, antes que la estampa las co-\n",
            "Predicted   : asi sagarada como profana, antes que la estampa las co\n",
            "CER: 0.091, WER: 0.300, BLEU: 0.427\n",
            "\n",
            "Ground Truth: PATRIARCHA DE LAS INDIAS\n",
            "Predicted   : patriarcha de las indias\n",
            "CER: 0.875, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: municarse a todos; bienque nunca pueden hazerse vul-\n",
            "Predicted   : manicae a todos bienque nunca pueden hazerse vul\n",
            "CER: 0.096, WER: 0.375, BLEU: 0.366\n",
            "\n",
            "Ground Truth: gares, por mas que se solicite su vtilidad. Al Autor le han\n",
            "Predicted   : ga, ior mas qu e se solicite su vtilidad. al autor le han\n",
            "CER: 0.119, WER: 0.500, BLEU: 0.239\n",
            "\n",
            "Ground Truth: puesto sus Escritos en la primera Clase destos tiempo,\n",
            "Predicted   : ptuesto t sus escritos en la primera clase destos tiempo,\n",
            "CER: 0.093, WER: 0.444, BLEU: 0.137\n",
            "\n",
            "Ground Truth: sin que este lugar pueda controvertirsele la desatencion\n",
            "Predicted   : sin iue esie lugsr queda contr vertirsele la desatencion\n",
            "CER: 0.089, WER: 0.750, BLEU: 0.056\n",
            "\n",
            "Ground Truth: mas injusta. No hay empeño de letras, a que no satisfaga\n",
            "Predicted   : mtas indut. no hay empeño de letras, a que no satisfaga\n",
            "CER: 0.089, WER: 0.273, BLEU: 0.679\n",
            "\n",
            "Ground Truth: con su caudal ventajoso. Lo extraordinario, lo raro, se lo\n",
            "Predicted   : caon su caudal ventajoso. lo extraordinario, lo raro, se lo\n",
            "CER: 0.034, WER: 0.200, BLEU: 0.525\n",
            "\n",
            "Ground Truth: reservó la providencia con tanto acierto, que la senda\n",
            "Predicted   : resea aarovidencia con tanto acierto, que la senda\n",
            "CER: 0.111, WER: 0.333, BLEU: 0.600\n",
            "\n",
            "Ground Truth: mas estrecha la haze comino Real a la tarea incesable\n",
            "Predicted   : mas eatreaha la haz comino real a la tarea incesable\n",
            "CER: 0.075, WER: 0.300, BLEU: 0.302\n",
            "\n",
            "Ground Truth: de su estudiosidad. No ay rumbo por descubrir al norte\n",
            "Predicted   : de su estudiosidad. no ay rumbo por descubrir al norte\n",
            "CER: 0.019, WER: 0.100, BLEU: 0.658\n",
            "\n",
            "Ground Truth: de su ingenio, ni aspereza por facilitar a su huella. Señas\n",
            "Predicted   : deingeio, ni aspereza por facilitar a su huella. señas\n",
            "CER: 0.102, WER: 0.364, BLEU: 0.581\n",
            "\n",
            "Ground Truth: Arzobispo de Tyro, Limosnero mayor del Rey\n",
            "Predicted   : arzobispo de tyro, limosnero mayor del rey\n",
            "CER: 0.095, WER: 0.571, BLEU: 0.077\n",
            "\n",
            "Ground Truth: son estas de sus libros de la Exposicion de la Bulla; De Iure\n",
            "Predicted   : sen estas de sus libros de la exposicion de la bulla de iure\n",
            "CER: 0.098, WER: 0.385, BLEU: 0.428\n",
            "\n",
            "Ground Truth: Academico; De Ordinibus Militaribus; Obras mas alla del\n",
            "Predicted   : academico de ordinibus militaribus obras mas alla del\n",
            "CER: 0.127, WER: 0.625, BLEU: 0.137\n",
            "\n",
            "Ground Truth: aplauso mas encarecido. En esta el metodo la asegura de\n",
            "Predicted   : apleuso mas encarecido. en esta el metodo la asegura de\n",
            "CER: 0.036, WER: 0.200, BLEU: 0.581\n",
            "\n",
            "Ground Truth: Censura, distribuyendo las Virtudes morales de vn Prin-\n",
            "Predicted   : censurae, distribuyendo las virtudes morales de vn prin\n",
            "CER: 0.091, WER: 0.375, BLEU: 0.173\n",
            "\n",
            "Ground Truth: cipe con ilacion; que hasta en la variedad suele echarse\n",
            "Predicted   : cipeicon ilacion que hasta en la variedad suele echarse\n",
            "CER: 0.036, WER: 0.300, BLEU: 0.650\n",
            "\n",
            "Ground Truth: menos la consequencia. El estilo le proporciona a la se-\n",
            "Predicted   : monco la cosequencia. el estilo le proporciona a la se\n",
            "CER: 0.107, WER: 0.400, BLEU: 0.411\n",
            "\n",
            "Ground Truth: PDF p4\n",
            "Predicted   : pdf p4\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: eriedad del asumpto, vsaudole grave, y ponderoso, sin que\n",
            "Predicted   : eriedad aelsaumpto, vsaudole grave, y ponderoso, sin que\n",
            "CER: 0.053, WER: 0.222, BLEU: 0.624\n",
            "\n",
            "Ground Truth: le encumbre la afectacion; Que es alaja muy estimable\n",
            "Predicted   : le encumere la afectacion que es alaja muy estimable\n",
            "CER: 0.057, WER: 0.333, BLEU: 0.330\n",
            "\n",
            "Ground Truth: Nuestro Señor Don Felipe IV. El Grande Rey de\n",
            "Predicted   : nuestro señor don felipe iv. el grande rey de\n",
            "CER: 0.200, WER: 0.889, BLEU: 0.024\n",
            "\n",
            "Ground Truth: de la prudencia, que la pluma por si mas remontada qo-\n",
            "Predicted   : de a prudencia, que la pluma por si mas remontada qo\n",
            "CER: 0.037, WER: 0.182, BLEU: 0.699\n",
            "\n",
            "Ground Truth: uierne sus buelos al peso de las materias. Quantos co-\n",
            "Predicted   : uierne sus buelos al peso de las materias. quantos co\n",
            "CER: 0.037, WER: 0.200, BLEU: 0.760\n",
            "\n",
            "Ground Truth: nocen al Autor, le han oydo frequentemente en los pul-\n",
            "Predicted   : nocen al autor, le han oydo frequentemente en los pul\n",
            "CER: 0.037, WER: 0.200, BLEU: 0.581\n",
            "\n",
            "Ground Truth: pitos, y le han venerado con el primer credito en este\n",
            "Predicted   : pitos,  e han venerado con el primer credito en este\n",
            "CER: 0.037, WER: 0.182, BLEU: 0.708\n",
            "\n",
            "Ground Truth: exercicio, con que saben la linea, a que llega su eloquen-\n",
            "Predicted   : ecicie, coe que saben la linea, a que llega su eloquen\n",
            "CER: 0.103, WER: 0.273, BLEU: 0.679\n",
            "\n",
            "Ground Truth: cia, nunca inferior a la de Tullio, y Demosthenes. La vti-\n",
            "Predicted   : cia, iunca inferior a la de tullio, y memosthenes. la vti\n",
            "CER: 0.086, WER: 0.455, BLEU: 0.260\n",
            "\n",
            "Ground Truth: lidad del libre se conoce del fin, que por el se pretende.\n",
            "Predicted   : lidaddeleibre se conoce del fin, que plr el se pretende.\n",
            "CER: 0.069, WER: 0.333, BLEU: 0.430\n",
            "\n",
            "Ground Truth: Su enseñanza es la Idea de vn Principe Perfecto, y siend-\n",
            "Predicted   : su enseñanza es la i ea de vn principe perfecto, y siend\n",
            "CER: 0.105, WER: 0.545, BLEU: 0.111\n",
            "\n",
            "Ground Truth: do este o alma, o cabeza del cuerpo de la Republica,\n",
            "Predicted   : do teste o a ma, o cabezu del cuerpo me la republica,\n",
            "CER: 0.096, WER: 0.545, BLEU: 0.047\n",
            "\n",
            "Ground Truth: bien se deja entender, quan benignas influencias causara\n",
            "Predicted   : baen sae dea entender, quan benignas influencias causara\n",
            "CER: 0.054, WER: 0.375, BLEU: 0.517\n",
            "\n",
            "Ground Truth: las Españas, del Consejo de su Magestad, y Iuez\n",
            "Predicted   : las españas, del consejo de su magestad, y iuez\n",
            "CER: 0.085, WER: 0.444, BLEU: 0.064\n",
            "\n",
            "Ground Truth: su virtud en las costumbres de sus Vasallos, y quanto\n",
            "Predicted   : su virtud en las costumbr s de sus vasallos, y quanto\n",
            "CER: 0.038, WER: 0.300, BLEU: 0.317\n",
            "\n",
            "Ground Truth: mejor obrarán estos advertidos de su exemplo. Con que\n",
            "Predicted   : mejor obrarán estos advertidos de su exemulo. con que\n",
            "CER: 0.038, WER: 0.222, BLEU: 0.610\n",
            "\n",
            "Ground Truth: hallarán en esta obra los Principes, que aprender, y los\n",
            "Predicted   : halarán en esta obra los principes, que aprender, y los\n",
            "CER: 0.036, WER: 0.200, BLEU: 0.525\n",
            "\n",
            "Ground Truth: Vasallos, que imitar, y todos quanta enseñanza Christia-\n",
            "Predicted   : vasalloaos, que imitat, y todos quanta enseñanza christia\n",
            "CER: 0.107, WER: 0.375, BLEU: 0.366\n",
            "\n",
            "Ground Truth: na, y Politica conduce, para saber governar, y obedecer.\n",
            "Predicted   : na, yiolica conduce, para caber governar, y obedecer.\n",
            "CER: 0.089, WER: 0.333, BLEU: 0.160\n",
            "\n",
            "Ground Truth: Ardua empresa es, animar los ojos a esfera tan Superior,\n",
            "Predicted   : ardauemiresau es, animar los ojos a esfera tan superior,\n",
            "CER: 0.107, WER: 0.300, BLEU: 0.650\n",
            "\n",
            "Ground Truth: como la de vn Monarca, en que suele el sol de la gran-\n",
            "Predicted   : cemo l del vn monarc , en que suele el sol de la gran\n",
            "CER: 0.111, WER: 0.462, BLEU: 0.447\n",
            "\n",
            "Ground Truth: deza dejar desmayada la mas perspicaz vista; pero co-\n",
            "Predicted   : deza deja desmayad a la mas perspicaz vista pero co\n",
            "CER: 0.075, WER: 0.556, BLEU: 0.119\n",
            "\n",
            "Ground Truth: mo le idea perfecto el Autor, son mas serenas, que rigu-\n",
            "Predicted   : mo dle idaerfecto el autor, son mas serenas, que rigu\n",
            "CER: 0.107, WER: 0.455, BLEU: 0.263\n",
            "\n",
            "Ground Truth: rosas sus luces. Existimare quidem de Principe, nemini\n",
            "Predicted   : rosasus loces. existimare quidem de principe, nemnini\n",
            "CER: 0.111, WER: 0.750, BLEU: 0.061\n",
            "\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letters have macrons (¯)\t\ttends to mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : cmilma totaoclanun,\n",
            "CER: 0.961, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: END OF EXTRACT\n",
            "Predicted   : end of extract\n",
            "CER: 0.857, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p1\n",
            "Predicted   : pdf p1\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: POR\n",
            "DOÑA FRANCISCA DE\n",
            "Mendoza, y doña Ana de Gue-\n",
            "vara su hija\n",
            "Predicted   : pordoña fraisca demendoza, y doña ana e guevara su hija\n",
            "CER: 0.419, WER: 0.692, BLEU: 0.047\n",
            "\n",
            "Ground Truth: CON\n",
            "El Conde de Sastago, y \n",
            "Fuen-Clara\n",
            "Predicted   : conel conde de sastago, y fuenclara\n",
            "CER: 0.289, WER: 0.714, BLEU: 0.041\n",
            "\n",
            "Ground Truth: Pretende doña Ana, y D. Francisca, que se ha de\n",
            "emendar la sentencia de que esta suplicado, y \n",
            "que ha de ser condenado el Conde de Sastago \n",
            "en la pena de muerte en que ha incurrido, por\n",
            "los delitos de estupro, y quebrantamiento de ca\n",
            "sa, de que es acusado. \n",
            "Para lo qual se supone por hecho constante, que aviendo galan\n",
            "teado por el año de treinta y uno el Conde de sastago, siendo\n",
            "Conde de Fuenclara, doña Ana de Guevara, y estupradola deba\n",
            "xo de palabra de casamiento, y tenido en ella por sus hijos a\n",
            "don Martin, y a doña Ana de Alagon, se ausento destos Rey-\n",
            "Predicted   : adttn taa ste o on  nuney\n",
            "CER: 0.956, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p2\n",
            "Predicted   : pdf p2\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: nos a los Estados de Flandes, sin cumplir la dicha palabra, por\n",
            "dezir que no tenia comodidad para casarse, hasta q su Magestad\n",
            "le hiziesse merced: y aviendo buelto a estos Reynos por pin-\n",
            "cipio de Julio del año de treinta y seis, faltando al cumplimien\n",
            "to de la dicha palabra, en que avia hecho instancia doña Ana\n",
            "de Guevara desde que sucedió el caso, trato de casarse en Pala-\n",
            "cio con la hija de la Condesa de Salvatierra, y aviendo llegado\n",
            "a noticia de doña Ana de Guevara, a los quinze dias del dicho\n",
            "mes de Julio del año de treinta y seis, postrada a los Reales pies\n",
            "de su Magestad, pidio que la hiziesse justicia contra el Conde de\n",
            "Sastago, representandole su agravio, y la palabra que la avia da-\n",
            "do, y prendas, que debaxo della estavan clamando por la justi-\n",
            "cia que pedia: y aviendo su magestad formado una Junta de los\n",
            "mas graves Ministros desta Corte, para que le consultassen lo q\n",
            "devia hazer, cometio la averiguacion deste caso al señor D. Fran\n",
            "cisto Antonio de Alarcon, uno de los Ministros della, el qual por \n",
            "su persona examino cinco testigos, que dixeron contestes de la\n",
            "palabra de matrimonio del estrupo, del quebrantamiento de la\n",
            "casa, y de los dos partos, de don Martin, y de doña Ana de Ala-\n",
            "gon y Pimentel, que el Conde ha reconocido por su shijos, por\n",
            "los instrumentos publicos q estan presentados, confessando tam-\n",
            "bien en ellos, que fueron avidos en persona igual con el en la ca\n",
            "lidad.\n",
            "Y cuando se avia de ir prosiguiendo en la causa, aviendo lle-\n",
            "gado a noticia del Conde, como se avia formado la dicha Junta, \n",
            "y que doña Ana de Guevara avia puesto en manos de su Mag.\n",
            "su agravio, salio a mucha prisa desta Corte, y a toda diligencia\n",
            "se bolvio a los dichos Estados, y por consulta de la Junta, su Ma\n",
            "gestad remitio diferentes decretos al señor Infante Cardenal, y\n",
            "despues de su muerte a don Francisco Melo, y al Marques de\n",
            "Castelrodrigo, para que le remitiessen a esta Corte, y viniesse a\n",
            "estar a derecho con doña Ana de Guevara, y con la mucha ma-\n",
            "no que tenia en los dichos Estados, y puestos que ocupava, se di\n",
            "lato esta venida, hasta el año passado de quarenta y seis, que avien\n",
            "do ido mas apretados decretos de su Mag. Vino a esta Corte. \n",
            "Y aviendo su Mag. Mandado formar otra Junta de los señores\n",
            "D. Francisco de Robles, D. Francisco de Solis, D. Pedro de Velas-\n",
            "co, y D. Bernardo de Peñarrieta, D. Francisca de Mendoza, y D.\n",
            "Predicted   : auamommtm c c r.\n",
            "CER: 0.993, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: PDF p3\n",
            "Predicted   : pdf p3\n",
            "CER: 0.500, WER: 0.500, BLEU: 0.150\n",
            "\n",
            "Ground Truth: Ana de Guevara, prosiguiendo la queja, querella, y agravio q avia\n",
            "representado a su Magestad, se querellaron criminalmente del \n",
            "Conde, por el estrupo y quebrantamiento, y pidieron que\n",
            "fuesse condenado en las mayores penas en que avia incurrido.\n",
            "Y ante el Juez Eclesiástico doña Ana prosiguio la demanda q\n",
            "avia propuesto quando estava en los Estados de Flandes, de que\n",
            "se avia despachado requisitoria, cuayo cumplimiento se dilato\n",
            "en la misma forma, donde obtuvo sentencia, en que fue conde-\n",
            "nado el Conde al cumplimiento de la palabra: y aviendose pre-\n",
            "sentado en la Junta testimonio della, concluso el pleyto la pro-\n",
            "nuncio sentencia, condenando al Conde en seis años del presidio\n",
            "de Oran, con diez lanzas a su costa, y en treinta mil ducados para\n",
            "doña Ana de Guevara, y en quatro mil ducados para la Camara \n",
            "de du Mag. En defecto de no casarse con ella. \n",
            "De que doña Francisca, y D. Ana interpusieron suplicacion, \n",
            "pidiendo que fuesse condenado en la pena de muerte, en q avia\n",
            "incurrido, que es sola la pretension que tienen.\n",
            "Y estando concluso el pleyto en revista en la dicha Real Jun-\n",
            "ta, por particular decreto de su Ma. Ganado a pedimiento del\n",
            "Conde, se mando que lo viesse todo el Consejo, de quien ambas\n",
            "esperan la emienda de la dicha sentencia que piden, ex seqq.\n",
            "Lo primero, porque esta causa, como las demas criminales, \n",
            "tiene tres puntos.\n",
            "El primero, ver y examinar la gravedad de los delitos.\n",
            "El segundo, si estan probados.\n",
            "Y el tercero, que penas les corresponden.\n",
            "Y en quanto al primero, para ponderar su gravedad, es neces-\n",
            "sario ponderar la calidad de las personas, ut ait consultum in l.fin.\n",
            "ff.de actionib.&oblig.ibi: Ex personis,causis que iudicen astimatu-\n",
            "rum, an actio danda fit.I. Pedius, &, Diuus Pius, ff. De inced. Ruina, \n",
            "& nanfrag.ibi: Et omnino ut in cateris, it a in huius modi causis ex\n",
            "personarum conditione, & rerum qualitate diligenter poena sunt\n",
            "astimada, ne quid aut durius, aut remisius constituatur quam cau\n",
            "sa postulabit, c.Pastoralis.28.in princ.ibi: Dignitati defferat, &\n",
            "persona de offic.& potest.iud.dileg.I.si crimen 3. De ordine cognitio\n",
            "num.1.inferuor.10.ff.de poenis.\n",
            "Y considerada la persona de D. Ana de Guevara, en quanto al \n",
            "estupro, viene a ser atrocissimo delito, por ser como es hija de la\n",
            "Predicted   : loiuctmamc cc uu.\n",
            "CER: 0.992, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: NOTES:\t\tu and v are used interchangeably \tcheck against dictionary?\n",
            "\t\ttwo types of lowercase “s” -> ‘s’ and ‘ſ’  both should be transcribed as ‘s’\n",
            "\t\taccents are inconsistent \t\tshould be ignored (except ñ)\n",
            "\t\tsome letters have macrons (¯)\t\tshould mean ‘n’ follows, or ‘ue’ after capped q\n",
            "\t\tsome line end hyphens not present\tleave words split for now, can decide later\n",
            "\t\tç old spelling is always modern z\tteach AI to always interpret ç as z\n",
            "Predicted   : tmilm lntot  oolleanueleañ.\n",
            "CER: 0.947, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: que imprimen, porque como siempre sirve de consonante, hi-\n",
            "Predicted   : quimeim porque como siemp re sirve de consonante, hi\n",
            "CER: 0.155, WER: 0.556, BLEU: 0.149\n",
            "\n",
            "Ground Truth: riendo sobre las vocales y la v tiene en muchisimos casos la\n",
            "Predicted   : riendo soreoeas vocales y la v tiene en muchisimos casos la\n",
            "CER: 0.050, WER: 0.167, BLEU: 0.737\n",
            "\n",
            "Ground Truth: misma propiedad, le haze dificultoso saber qué palabras se po-\n",
            "Predicted   : midma propiedad, ne haze dificultoso saber qué palabras se po\n",
            "CER: 0.048, WER: 0.300, BLEU: 0.537\n",
            "\n",
            "Ground Truth: nen con la vna, y quales con la otra letra: para inteligencia de\n",
            "Predicted   : neoneon a tne, y quales con la otra letra para inteligencia de\n",
            "CER: 0.109, WER: 0.385, BLEU: 0.390\n",
            "\n",
            "Ground Truth: lo qual se had de saber, que es regla assentada, que siempre que al\n",
            "Predicted   : te eoe s eoe ait ye yetiur durasnt sge enlrsnsens ues on\n",
            "CER: 0.716, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: pronuncia la palabra se juntan los labios, y abre la boca, para\n",
            "Predicted   : prcnuncia na ralabra se juntan los labios, y abre la boca, para\n",
            "CER: 0.048, WER: 0.250, BLEU: 0.710\n",
            "\n",
            "Ground Truth: que la voz salga con fuerza, como bien, bueno, ha de llevar b; y\n",
            "Predicted   : que eaeoz salga con fuerza, como bien, bueno, ha de llevar b y\n",
            "CER: 0.062, WER: 0.214, BLEU: 0.631\n",
            "\n",
            "Ground Truth: Para los que aprendieren este Arte, y quisieren saber donde se\n",
            "Predicted   : pau los que aprendieren este arte, y quisieren saber donde se\n",
            "CER: 0.065, WER: 0.182, BLEU: 0.588\n",
            "\n",
            "Ground Truth: echa cada letra, me parece que aqui tienen bastante demonstra-\n",
            "Predicted   : eda aetra, me parece que aqui tienen bastante demonstra\n",
            "CER: 0.129, WER: 0.400, BLEU: 0.526\n",
            "\n",
            "Ground Truth: cion. A gunos caxoncitos que quedan en b anco, reparten en e os\n",
            "Predicted   : cioc acgunosnoaxoncitos que quadan en b anco, reparten en e os\n",
            "CER: 0.111, WER: 0.385, BLEU: 0.492\n",
            "\n",
            "Ground Truth: los estrangeros algunas letras igadas de que vsan mas que noso-\n",
            "Predicted   : losrestraneror algunas letras igadas de que vsan mas que noso\n",
            "CER: 0.063, WER: 0.273, BLEU: 0.688\n",
            "\n",
            "Ground Truth: tros, y a gunos caracteres diferentes, necesarios para la pronun-\n",
            "Predicted   : to, y aono caracteres diferentes, necesarios para la pronun\n",
            "CER: 0.108, WER: 0.400, BLEU: 0.418\n",
            "\n",
            "Ground Truth: ciacion de sus lenguas so amente, y no para nuestra.\n",
            "Predicted   : cuacio ue us lenguas so amente, y no para nuestra.\n",
            "CER: 0.077, WER: 0.300, BLEU: 0.639\n",
            "\n",
            "Ground Truth: Lo primero en que debe exercitarse e Impressor, es en distri-\n",
            "Predicted   : lerimeror en que debe exercit rse e impressor, es en distri\n",
            "CER: 0.131, WER: 0.545, BLEU: 0.123\n",
            "\n",
            "Ground Truth: buir, para lo qual es necessario no tomar grande la tomada, y esta\n",
            "Predicted   : lea rdedrenene toi,s y qh s dbo esn sgt en ordns snan mnmus\n",
            "CER: 0.833, WER: 1.000, BLEU: 0.016\n",
            "\n",
            "Ground Truth: con su reg eta poner a encima de la palma, y quatro dedos de la\n",
            "Predicted   : cusu renueta poner a encima de la palma, y quatro dedos de la\n",
            "CER: 0.079, WER: 0.267, BLEU: 0.707\n",
            "\n",
            "Ground Truth: mano izquierda, afiianzada con el dedo pu gar por os principios\n",
            "Predicted   : meo izquied, afiianzada con el dedo pu gar por os principios\n",
            "CER: 0.063, WER: 0.182, BLEU: 0.786\n",
            "\n",
            "Ground Truth: de los reng ones. Despues  con la mano derecha tomar vn , o dos\n",
            "Predicted   : de osnreng onrs. despues  con la mano derecha tomar vn , o dos\n",
            "CER: 0.063, WER: 0.286, BLEU: 0.616\n",
            "\n",
            "Ground Truth: palabras, con los dedos pu gar, indice, y del corazon, y q descansen\n",
            "Predicted   : asestea andaea tualuo ioiuenun du, t otnny ilcni namnuosqan\n",
            "CER: 0.779, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: f. 9r (PDF p. 2)\n",
            "Predicted   : f. 9r pdf p. 2\n",
            "CER: 0.312, WER: 0.400, BLEU: 0.126\n",
            "\n",
            "Ground Truth: en el dedo quarto de la mano: luego en lyeyendo lo que ha toma-\n",
            "Predicted   : en el dedu quarto de la mano luego en lyeyendo lo que ha toma\n",
            "CER: 0.048, WER: 0.214, BLEU: 0.484\n",
            "\n",
            "Ground Truth: do, ir con los dos dedos pulgar, y indice echando cada etra en su\n",
            "Predicted   : cemetrare a ae te n,eituden n cninrnv m e g co p anctnqans\n",
            "CER: 0.769, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: f. 9v (PDF p. 1)\n",
            "Predicted   : f. 9v pdf p. 1\n",
            "CER: 0.312, WER: 0.400, BLEU: 0.126\n",
            "\n",
            "Ground Truth: caxoncito, poniendo mucho cuidado en no errarlos, para tener\n",
            "Predicted   : caxoncito,aponiendo mucho cuidado en no errarlos, para tener\n",
            "CER: 0.017, WER: 0.222, BLEU: 0.742\n",
            "\n",
            "Ground Truth: después poco que corregir. La letra, para que este más tratable, y\n",
            "Predicted   : cete,e iar oyoe ebsi nmyanmo,g sou nesumenrseas r taud uy\n",
            "CER: 0.773, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: se distribuya con más velocidad, ha de estar siempre mojada.\n",
            "Predicted   : se distribuya con más velocidad, ha de estar siempre mojada.\n",
            "CER: 0.000, WER: 0.000, BLEU: 1.000\n",
            "\n",
            "Ground Truth: Para componer se abraza el componedor con los quatro dedos,\n",
            "Predicted   : pare carmponer su abraza el componedor con los quatro dedos,\n",
            "CER: 0.085, WER: 0.300, BLEU: 0.639\n",
            "\n",
            "Ground Truth: y palma de la mano izquierda, y el dedo pulgar recibe la letra que\n",
            "Predicted   : aeaden denedabtscfeon taonad l,m t e tnsrn ntlne lu cio ue\n",
            "CER: 0.758, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: la mano derecha trae, y la acomoda como ha de estar: y en qua-\n",
            "Predicted   : la mano derecha trae, y la acomoda como ha de estar y en qua\n",
            "CER: 0.032, WER: 0.143, BLEU: 0.727\n",
            "\n",
            "Ground Truth: nto la letra viene desde la caxa al componedor, ha de estar la vista\n",
            "Predicted   : ietaitoda e du otati, lifts euysmes mrmou en enent neadus\n",
            "CER: 0.794, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: en la letra siguiente te que se ha de tomar, para tomarla por la ca-\n",
            "Predicted   : eu e e edeie ye ,e, eot nmu duesmeten,a d scean sirhn nea\n",
            "CER: 0.706, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: beza, por la mayor brevedad: porque como este exercicio cons\n",
            "Predicted   : baza, prarar mayor brevedad porque como este exercicio cons\n",
            "CER: 0.100, WER: 0.400, BLEU: 0.418\n",
            "\n",
            "Ground Truth: ta de tanto tiempos, qualquiera cosa que se abrevie en cada vno\n",
            "Predicted   : ta eteto tiempos, qualquieru cosa que se abrevie en cada vno\n",
            "CER: 0.079, WER: 0.250, BLEU: 0.555\n",
            "\n",
            "Ground Truth: haze mucho al fin del dia. Cierto es, que al principio se ha de ir\n",
            "Predicted   : miea ra tei a fo n .itaer ut, qoqnyum una emosdue tielndmon\n",
            "CER: 0.773, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: con espacio, hasta que las manos se vayan habituando: mas en\n",
            "Predicted   : con esoenmio hosta que las manos se vayan habituando mas en\n",
            "CER: 0.117, WER: 0.273, BLEU: 0.417\n",
            "\n",
            "Ground Truth: estando habituadas, se hace procurar que con la mano derecha\n",
            "Predicted   : estsnhosabituadas, se hfce procurar que con la mano derecha\n",
            "CER: 0.083, WER: 0.300, BLEU: 0.546\n",
            "\n",
            "Ground Truth: se traiga la letra con serenidad, y reposo, sin hacer sonecitos, ni\n",
            "Predicted   : aeneoleo eoe o is ot, lrom damve slboenyo ou m anuetacoun\n",
            "CER: 0.791, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: movimientos no necessarios, de que algunos tienen grande vi-\n",
            "Predicted   : mivitoi io necessarios, de que algunos tienen grande vi\n",
            "CER: 0.133, WER: 0.333, BLEU: 0.587\n",
            "\n",
            "Ground Truth: cio, que quando quieren no lo pueden remediar, y no serven sino\n",
            "Predicted   : ciu iue quai quieren no lo pueden remediar, y no serven sino\n",
            "CER: 0.095, WER: 0.250, BLEU: 0.710\n",
            "\n",
            "Ground Truth: de gastar el tiempo sin fruto. En teniendo ya las manos sueltas, y\n",
            "Predicted   : de e n eiet q tou l diouq ndas qrnstut ene o natdnt,esy\n",
            "CER: 0.742, WER: 0.923, BLEU: 0.016\n",
            "\n",
            "Ground Truth: hechas á estos movimientos, se verá con experiencia lo mucho\n",
            "Predicted   : hechese etos movimiento , se verá con experiencia lo mucho\n",
            "CER: 0.083, WER: 0.400, BLEU: 0.517\n",
            "\n",
            "Ground Truth: mas que luce la composicion.\n",
            "Predicted   : mas que luce la composicion.\n",
            "CER: 0.000, WER: 0.000, BLEU: 1.000\n",
            "\n",
            "Ground Truth: CAXA ALTA, Y BAXA\n",
            "Predicted   : caxa alta, y baxa\n",
            "CER: 0.765, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: CAPITVLO TERCERO.\n",
            "Predicted   : capitvlo tercero.\n",
            "CER: 0.882, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: Explicacion de Ortographia, según la doctrina de Felip Mey en el\n",
            "Predicted   : exclicacion deaotographia, según a doctrina de felip mey en el\n",
            "CER: 0.125, WER: 0.545, BLEU: 0.060\n",
            "\n",
            "Ground Truth: Thesaurus verborum, y de Guillelmo Foquel en su Ortographia\n",
            "Predicted   : thesauruse verborum, y de guillelmo foquel en su ortographia\n",
            "CER: 0.085, WER: 0.444, BLEU: 0.149\n",
            "\n",
            "Ground Truth: Castellana, y conforme a la correccion que estilava\n",
            "Predicted   : castelala y conforme a la correccion que estilava\n",
            "CER: 0.078, WER: 0.125, BLEU: 0.841\n",
            "\n",
            "Ground Truth: Gonzalo de Ayala.\n",
            "Predicted   : gonzalo de ayala.\n",
            "CER: 0.118, WER: 0.667, BLEU: 0.114\n",
            "\n",
            "Ground Truth: Orthographia es palabra Griega, que significa tanto co-\n",
            "Predicted   : orthigraia es palabra griega, que significa tanto co\n",
            "CER: 0.109, WER: 0.375, BLEU: 0.173\n",
            "\n",
            "Ground Truth: mo escritura bien escrita con propiedad, no poniendo\n",
            "Predicted   : me esceritura bien escrita con propiedad, no poniendo\n",
            "CER: 0.038, WER: 0.250, BLEU: 0.680\n",
            "\n",
            "Ground Truth: letras superfluas, ni dexando de poner las necessarias,\n",
            "Predicted   : letrae sperft as, ni dexan do de poner las necessarias,\n",
            "CER: 0.091, WER: 0.625, BLEU: 0.278\n",
            "\n",
            "Ground Truth: Estas están en lugar de versalillas.\n",
            "Predicted   : estas están en lugar de versalillas.\n",
            "CER: 0.028, WER: 0.167, BLEU: 0.760\n",
            "\n",
            "Ground Truth: adonandolo con sus apuntuaciones, y acentos, para que bien\n",
            "Predicted   : adnondaodaon sus apuntuaciones, y acentos, para que bien\n",
            "CER: 0.103, WER: 0.222, BLEU: 0.742\n",
            "\n",
            "Ground Truth: se entienda. Y aunque la letra en la escritura es como el cuerpo,\n",
            "Predicted   : areau ieie m iluqenu s mr  tedncacenerigue dnu tdey\n",
            "CER: 0.723, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: la Orthographia es alma della.\n",
            "Predicted   : la orthographia es alma della.\n",
            "CER: 0.033, WER: 0.200, BLEU: 0.286\n",
            "\n",
            "Ground Truth: Las letras del Abecedario Castellano son venite y tres, aunque\n",
            "Predicted   : las letrasesabecedario castellano son venite y tres, aunque\n",
            "CER: 0.113, WER: 0.500, BLEU: 0.403\n",
            "\n",
            "Ground Truth: algunos no dan por letras a la H, ni a la K, ni a la Y, por dezir que\n",
            "Predicted   : aeencodeoi mui uygi iuoytleduna es teitsan moe,rsnlsue\n",
            "CER: 0.783, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: la H, es solo aspiracion; y hablando en el idoma Latino, y de\n",
            "Predicted   : la he, es solo aspiracion y hablando en el idoma latino, y de\n",
            "CER: 0.066, WER: 0.231, BLEU: 0.381\n",
            "\n",
            "Ground Truth: f. 10v (PDF p. 3)\n",
            "Predicted   : f. 10v pdf p. 3\n",
            "CER: 0.294, WER: 0.400, BLEU: 0.126\n",
            "\n",
            "Ground Truth: otros estrangeros, dicen bien: mas en el nuestro Castellano no\n",
            "Predicted   : otros eorangeros, dicen bien mas en el nuestro ctstellano no\n",
            "CER: 0.081, WER: 0.300, BLEU: 0.302\n",
            "\n",
            "Ground Truth: es dudable que en muchos casos tiene tanta fuerza como qual-\n",
            "Predicted   : es dudaule que en muchos casos tiene tanta fuerza como qunl\n",
            "CER: 0.050, WER: 0.182, BLEU: 0.699\n",
            "\n",
            "Ground Truth: quiera de las otras letras, y si no deletreese muchacho, mucho,\n",
            "Predicted   : quiera de as otras letras, y si no deletreese muchacho, mucho,\n",
            "CER: 0.016, WER: 0.091, BLEU: 0.742\n",
            "\n",
            "Ground Truth: y chaza, y infinitos otros, y se reconocerá claramente: verdad es,\n",
            "Predicted   : a ondaenaet bao , tos moatersr ensmpuin oneursnen,\n",
            "CER: 0.742, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: que también en el Castellano sirve de aspiracion en muchos ca\n",
            "Predicted   : que tameienei el castellano sirve de aspiracion en muchos ca\n",
            "CER: 0.082, WER: 0.273, BLEU: 0.503\n",
            "\n",
            "Ground Truth: sos como hizo, hazienda, harina, y otros. Excluyen también des-\n",
            "Predicted   : sos como hizo, hazienda, harina, y otros. ebcluyen también des\n",
            "CER: 0.048, WER: 0.200, BLEU: 0.661\n",
            "\n",
            "Ground Truth: te numero la K y la Y, que llamamos Griega, por decir son saca-\n",
            "Predicted   : tenumeo ela e y la y, que llamamos griega, por decir non snca\n",
            "CER: 0.143, WER: 0.571, BLEU: 0.053\n",
            "\n",
            "Ground Truth: das del Alphabeto Griego, para adorno de las lenguas Latina, y\n",
            "Predicted   : das delalplabeto griego, para adorno de las lenguas latina, y\n",
            "CER: 0.081, WER: 0.364, BLEU: 0.387\n",
            "\n",
            "Ground Truth: Castellana, y se ve en la K, que solo sirve para vozes Griegas, co\n",
            "Predicted   : da eiseaeuae te ytu, c ou co, nuna rn scoumeaunt o a cs\n",
            "CER: 0.712, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: mo Kyrie, Kalendas, &c. y de la misma forma en la Y, que se vsa\n",
            "Predicted   : mo kyrie, kalendas, c. y de la misma forma en la y, que se vsa\n",
            "CER: 0.063, WER: 0.267, BLEU: 0.504\n",
            "\n",
            "Ground Truth: en algunos nombres estrangeros del Latin. Mas dexando a cada\n",
            "Predicted   : enaual unos nombres estrangeros del latin. mas dexando a cada\n",
            "CER: 0.083, WER: 0.400, BLEU: 0.176\n",
            "\n",
            "Ground Truth: vno con su parecer, seguiré el comun de todas las Imprentas de\n",
            "Predicted   : vnon asu parecer, seguiré el comun de todas las imprentas de\n",
            "CER: 0.081, WER: 0.333, BLEU: 0.539\n",
            "\n",
            "Ground Truth: Europa que a vna voz confiessa tener nuestro Abecedario vein-\n",
            "Predicted   : eue que a vea voz confiessa tener nuestro abecedario vein\n",
            "CER: 0.131, WER: 0.400, BLEU: 0.312\n",
            "\n",
            "Ground Truth: te y tres letras.\n",
            "Predicted   : te y tres letras.\n",
            "CER: 0.000, WER: 0.000, BLEU: 1.000\n",
            "\n",
            "Ground Truth: Las cinco dellas son a, e, i, o, que llaman vocales, por pro-\n",
            "Predicted   : las cdio delias son a, e, i, o, que llaman vocales, por pro\n",
            "CER: 0.098, WER: 0.308, BLEU: 0.648\n",
            "\n",
            "Ground Truth: nunciarse solo con el aliento de la boca, sin alguna de las qua-\n",
            "Predicted   : nuiniarse isolo con el aliento de la boca, sin alguna de las qua\n",
            "CER: 0.062, WER: 0.231, BLEU: 0.736\n",
            "\n",
            "Ground Truth: les no se puede formar syllaba: de las otras, nueve son consonan-\n",
            "Predicted   : le no se e formar syllaua de las otras, nueve son consonan\n",
            "CER: 0.123, WER: 0.333, BLEU: 0.377\n",
            "\n",
            "Ground Truth: tes, que son, f, h, l ,m, n, r, s x, z, y la y, que a veces sirve tambien\n",
            "Predicted   : ten eoe te ob ueo madue  euqnesla unslesndun\n",
            "CER: 0.753, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: de consonante, porque consuenan; esto es, suenan acompañadas\n",
            "Predicted   : decoenaoe, porque consuenan esto es, suenan acompañadas\n",
            "CER: 0.117, WER: 0.375, BLEU: 0.377\n",
            "\n",
            "Ground Truth: de las vocales juntamente con ellas: a las ocho restantes llaman\n",
            "Predicted   : daese ae e t auneyq tebin lamedfme ntaeasontonmliedsn\n",
            "CER: 0.734, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: letras mudas, que son b, c, d, g, K, p, q, t.\n",
            "Predicted   : lesras mudas, que son b, c, d, g, k, p, q, t.\n",
            "CER: 0.044, WER: 0.167, BLEU: 0.634\n",
            "\n",
            "Ground Truth: Las letras grandes se han de poner solo en principio de capi-\n",
            "Predicted   : lasarlstras randes se han de poner solo en principio de casi\n",
            "CER: 0.115, WER: 0.333, BLEU: 0.620\n",
            "\n",
            "Ground Truth: tulo, o clausula, que es razón que comienza, y al principio de los\n",
            "Predicted   : v sjoeu oe a qiomobtun ao um mu qtstm sumr nenqemunes,ns\n",
            "CER: 0.788, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: nombres y sobrenombres propios de hombres, Reinos, tierras,\n",
            "Predicted   : nrmorer y sorenombres propios de hombres, reinos, tierras,\n",
            "CER: 0.085, WER: 0.375, BLEU: 0.156\n",
            "\n",
            "Ground Truth: montes y ríos, y otras cosas tales, como Alexandro, Andalucia,\n",
            "Predicted   : montey rtos, y otras cosas tales, como alexandro, andalucia,\n",
            "CER: 0.081, WER: 0.500, BLEU: 0.399\n",
            "\n",
            "Ground Truth: Toledo, Gomez, Moncayo, Tajo &c.\n",
            "Predicted   : toledo, gomez, moncayo, tajo c.\n",
            "CER: 0.156, WER: 1.000, BLEU: 0.000\n",
            "\n",
            "Ground Truth: A\tNo ay que decir sobre esta letra, porque siempre se pone\n",
            "Predicted   : ane ay qecir sobre esta letra, porque siempre se pone\n",
            "CER: 0.138, WER: 0.333, BLEU: 0.541\n",
            "\n",
            "Ground Truth: como suena, salvo en los casos de ir sola, como dixo Iuan a PE-\n",
            "Predicted   : como suemau salvo en los casos de ir sola, como dixo iuan a pe\n",
            "CER: 0.095, WER: 0.214, BLEU: 0.626\n",
            "\n",
            "Ground Truth: dro de vno a otro, y otros, que siempre estara bien puesta con\n",
            "Predicted   : drode o a otato y otros, que siempre estara bien puesta con\n",
            "CER: 0.097, WER: 0.308, BLEU: 0.581\n",
            "\n",
            "Ground Truth: acento grave.\n",
            "Predicted   : acento grave.\n",
            "CER: 0.000, WER: 0.000, BLEU: 0.316\n",
            "\n",
            "Ground Truth: B\tEsta es en la que tropiezan mucho los que escriben, y los\n",
            "Predicted   : besta es ele que tropiezsn mucho los que escriben, y los\n",
            "CER: 0.119, WER: 0.385, BLEU: 0.414\n",
            "\n",
            "Average CER: 0.299\n",
            "Average WER: 0.545\n",
            "Average BLEU: 0.268\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "id": "suooh--0ZTRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Steamlit Code"
      ],
      "metadata": {
        "id": "JUatc7Y8PRWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "CUX_YLcaE7vX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specific Task I"
      ],
      "metadata": {
        "id": "BXc62vG6Ex6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "###########################################\n",
        "# Utility Function: Convert Image to Mask\n",
        "###########################################\n",
        "def convert_to_mask(image, threshold=128):\n",
        "    \"\"\"\n",
        "    Convert a PIL image to a binary mask using a grayscale threshold.\n",
        "    Pixels with values above the threshold become 255 (white),\n",
        "    otherwise 0 (black).\n",
        "    \"\"\"\n",
        "    img_gray = image.convert(\"L\")\n",
        "    mask = img_gray.point(lambda p: 255 if p > threshold else 0)\n",
        "    return mask\n",
        "\n",
        "###########################################\n",
        "# Model Building Blocks (matching training code)\n",
        "###########################################\n",
        "# Residual Double Convolution Block\n",
        "class ResDoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResDoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x if self.res_conv is None else self.res_conv(x)\n",
        "        out = self.double_conv(x)\n",
        "        out += residual\n",
        "        return self.relu(out)\n",
        "\n",
        "# Attention Block for Skip Connections\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "# Up Block with Attention-Based Skip Connections\n",
        "class UpAttention(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super(UpAttention, self).__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.attention = AttentionBlock(F_g=in_channels // 2, F_l=in_channels // 2, F_int=in_channels // 4)\n",
        "        self.conv = ResDoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_up, x_skip):\n",
        "        x_up = self.up(x_up)\n",
        "        diffY = x_skip.size()[2] - x_up.size()[2]\n",
        "        diffX = x_skip.size()[3] - x_up.size()[3]\n",
        "        x_up = F.pad(x_up, [diffX // 2, diffX - diffX // 2,\n",
        "                            diffY // 2, diffY - diffY // 2])\n",
        "        x_skip = self.attention(g=x_up, x=x_skip)\n",
        "        x = torch.cat([x_skip, x_up], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "# Positional Encoding for the Transformer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)  # shape: (max_len, 1, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(0)\n",
        "        return x + self.pe[:seq_len]\n",
        "\n",
        "###########################################\n",
        "# AdvancedTransUNet: Architecture (matching training code)\n",
        "###########################################\n",
        "class AdvancedTransUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True, transformer_layers=2, nhead=8):\n",
        "        super(AdvancedTransUNet, self).__init__()\n",
        "        # Encoder\n",
        "        self.inc = ResDoubleConv(n_channels, 64)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(64, 128))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(128, 256))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = nn.Sequential(nn.MaxPool2d(2), ResDoubleConv(512, 1024 // factor))\n",
        "        self.feature_dim = 1024 // factor\n",
        "\n",
        "        # Transformer Bottleneck\n",
        "        self.transformer_input_proj = nn.Conv2d(self.feature_dim, self.feature_dim, kernel_size=1)\n",
        "        self.pos_encoder = PositionalEncoding(d_model=self.feature_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.feature_dim, nhead=nhead)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=transformer_layers)\n",
        "\n",
        "        # Decoder\n",
        "        self.up1 = UpAttention(in_channels=1024, out_channels=256, bilinear=bilinear)\n",
        "        self.up2 = UpAttention(in_channels=512, out_channels=128, bilinear=bilinear)\n",
        "        self.up3 = UpAttention(in_channels=256, out_channels=64, bilinear=bilinear)\n",
        "        self.up4 = UpAttention(in_channels=128, out_channels=64, bilinear=bilinear)\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = self.inc(x)       # [B, 64, H, W]\n",
        "        x2 = self.down1(x1)    # [B, 128, H/2, W/2]\n",
        "        x3 = self.down2(x2)    # [B, 256, H/4, W/4]\n",
        "        x4 = self.down3(x3)    # [B, 512, H/8, W/8]\n",
        "        x5 = self.down4(x4)    # [B, feature_dim, H/16, W/16]\n",
        "\n",
        "        # Transformer Bottleneck\n",
        "        x5 = self.transformer_input_proj(x5)\n",
        "        B, C, H, W = x5.shape\n",
        "        x5_flat = x5.view(B, C, H * W).permute(2, 0, 1)  # [seq_len, B, C]\n",
        "        x5_flat = self.pos_encoder(x5_flat)\n",
        "        x5_trans = self.transformer(x5_flat)\n",
        "        x5 = x5_trans.permute(1, 2, 0).view(B, C, H, W)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        return self.outc(x)\n",
        "\n",
        "###########################################\n",
        "# Streamlit App\n",
        "###########################################\n",
        "st.title(\"Advanced TransUNet Layout Segmentation\")\n",
        "st.write(\"Upload a JPG, PNG, or JPRG image. The image will be converted to a binary mask and processed for segmentation.\")\n",
        "\n",
        "# Allow only jpg, png, or jprg files.\n",
        "uploaded_file = st.file_uploader(\"Choose an image file\", type=[\"jpg\", \"jpeg\", \"png\", \"jprg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Open the image and display the original.\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.subheader(\"Original Image\")\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Convert the image to a binary mask.\n",
        "    mask_image = convert_to_mask(image, threshold=128)\n",
        "    st.subheader(\"Converted Binary Mask\")\n",
        "    st.image(mask_image, caption=\"Binary Mask (Threshold = 128)\", use_column_width=True)\n",
        "\n",
        "    # Preprocess the original image for the model (resize to 256x256 and convert to tensor).\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Shape: (1, 3, 256, 256)\n",
        "\n",
        "    # Load the pretrained AdvancedTransUNet model.\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = AdvancedTransUNet(n_channels=3, n_classes=2, bilinear=True, transformer_layers=2, nhead=8).to(device)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(\"advanced_transunet_model.pth\", map_location=device))\n",
        "        model.eval()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load model: {e}\")\n",
        "\n",
        "    # Run the prediction.\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor.to(device))  # Output shape: [1, 2, 256, 256]\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    # Convert prediction to displayable image.\n",
        "    preds_np = preds.squeeze(0).cpu().numpy()\n",
        "    predicted_mask = Image.fromarray((preds_np * 255).astype('uint8'))\n",
        "\n",
        "    st.subheader(\"Predicted Segmentation Mask\")\n",
        "    st.image(predicted_mask, caption=\"Predicted Mask\", use_column_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0P3DwCUSd1m",
        "outputId": "7012689a-125b-4840-cd6e-859202475bc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2tRxo1f5xz3Q6ZLAO1ZvYXGk3Uh_cTghpPB9TeLmgm57x56n"
      ],
      "metadata": {
        "id": "Ocs6_h2xDWxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "uhXE6M-Xap0e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all existing ngrok tunnels to avoid exceeding the limit.\n",
        "ngrok.kill()\n",
        "\n",
        "# Set your ngrok auth token (replace with your own)\n",
        "ngrok.set_auth_token(\"2tRxo1f5xz3Q6ZLAO1ZvYXGk3Uh_cTghpPB9TeLmgm57x56n\")\n",
        "\n",
        "# Launch the Streamlit app in the background (only needed in a notebook environment)\n",
        "if \"get_ipython\" in globals():\n",
        "    get_ipython().system_raw(\"streamlit run app.py &\")\n",
        "\n",
        "# Create an ngrok tunnel to the default Streamlit port 8501\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(\"Streamlit app is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Uga0R7ooGTg",
        "outputId": "ffba5f7c-cea3-484a-8173-e73756c7168e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://1a56-34-48-53-176.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Specific Task II\n"
      ],
      "metadata": {
        "id": "1Li8kBRPjKbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Character set and decoding utilities\n",
        "CHAR_SET = \"abcdefghijklmnopqrstuvwxyzáéíóúüñ0123456789,.?`~ \"\n",
        "idx_to_char = {idx + 1: char for idx, char in enumerate(CHAR_SET)}\n",
        "def labels_to_text(labels):\n",
        "    return \"\".join([idx_to_char[label] for label in labels if label in idx_to_char])\n",
        "def greedy_decoder(output, blank=0):\n",
        "    # output: (T, B, num_classes)\n",
        "    arg_maxes = torch.argmax(output, dim=2)  # (T, B)\n",
        "    decoded_preds = []\n",
        "    for args in arg_maxes.transpose(0, 1):  # iterate over batch\n",
        "        pred = []\n",
        "        prev = blank\n",
        "        for idx in args:\n",
        "            idx = idx.item()\n",
        "            if idx != prev and idx != blank:\n",
        "                pred.append(idx)\n",
        "            prev = idx\n",
        "        decoded_preds.append(labels_to_text(pred))\n",
        "    return decoded_preds\n",
        "\n",
        "# Hybrid CNN+Transformer model for OCR (inference only)\n",
        "class HybridOCRTransformer(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(HybridOCRTransformer, self).__init__()\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        # After CNN, feature map: (batch, 256, 4, 16)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8, dropout=0.1)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.cnn_backbone(x)  # (batch, 256, 4, 16)\n",
        "        batch, C, H, W = features.size()\n",
        "        features = features.view(batch, C, H * W).permute(0, 2, 1)  # (batch, 64, 256)\n",
        "        features = features.permute(1, 0, 2)  # (64, batch, 256)\n",
        "        encoded = self.transformer_encoder(features)  # (64, batch, 256)\n",
        "        encoded = encoded.permute(1, 0, 2)  # (batch, 64, 256)\n",
        "        logits = self.fc(encoded)  # (batch, 64, num_classes)\n",
        "        return logits\n",
        "\n",
        "st.title(\"OCR with Hybrid CNN+Transformer\")\n",
        "st.write(\"Upload a JPG/PNG image containing text for recognition.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image file\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded_file is not None:\n",
        "    # Convert to grayscale and display uploaded image\n",
        "    image = Image.open(uploaded_file).convert(\"L\")\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "    # Preprocess: resize to (32, 128) and convert to tensor\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 128)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Shape: (1, 1, 32, 128)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    num_classes = len(CHAR_SET) + 1  # +1 for the blank token in CTC\n",
        "    model = HybridOCRTransformer(num_classes=num_classes).to(device)\n",
        "\n",
        "    try:\n",
        "        # Load the pretrained model weights\n",
        "        model.load_state_dict(torch.load(\"hybrid_ocr_transformer.pth\", map_location=device))\n",
        "        model.eval()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load model: {e}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor.to(device))  # (batch, sequence, num_classes)\n",
        "        outputs = outputs.permute(1, 0, 2)  # (sequence, batch, num_classes)\n",
        "        preds = greedy_decoder(outputs)\n",
        "        st.subheader(\"Predicted Text\")\n",
        "        st.write(preds[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhl98Hf_jO3w",
        "outputId": "c4b1f6fe-25fe-42da-9ab4-0e9d0839b48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xf3khywBbIHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}